{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZP2GeYU0Lwc"
      },
      "source": [
        "# Install libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgYh9E_6PRlz"
      },
      "outputs": [],
      "source": [
        "%pip install pytorch_fid torchmetrics scikit-image lpips piq  torch-fidelity piqa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h00KxoWy0Lwj"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUHkiB4HnAtr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "import cv2  # [[1]][[2]]\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import datetime\n",
        "from piqa import SSIM  # << Install with `pip install piqa` [[9]]\n",
        "import torch_fidelity\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import lpips\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import piqa\n",
        "from skimage.util import random_noise  # << Install first [[1]][[2]]\n",
        "import skimage.util  # << Add this import at the top of your file [[1]]\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SUtVDc1WaKi"
      },
      "source": [
        "# Variables for ECC GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAZ5UefNnCOk"
      },
      "outputs": [],
      "source": [
        "bs_c = '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/'\n",
        "dt_c = [bs_c+'Train/',bs_c+'Test/']\n",
        "\n",
        "bs = '/content/drive/.shortcut-targets-by-id/1UGQF2LHCrsyEmb1WB-Afz_en4bRRYQWv/Segmentation/'\n",
        "dt = [bs+'Original/',bs+'Ground_Truth/',bs+'Ground_Truth_New/',bs+'Original_New/']\n",
        "pths=['Basophil','Eosinophil','Lymphocyte','Monocyte','Neutrophil']\n",
        "# Faghat roo Basophil javab dade\n",
        "aim = 0 # 'Basophil 0 ok','Eosinophil 1 ok','Lymphocyte 2 ok az 10-30','Monocyte 3 400 epoch az 300 be bad','Neutrophil 4 30 va 40 khoobe baghie ok nist'\n",
        "aim_pths = [d + pths[aim] + '/' for d in dt]  # << Corrected line [[1]][[2]]\n",
        "aim_pths_c = [d + pths[aim] + '/' for d in dt_c]  # << Corrected line [[1]][[2]]\n",
        "\n",
        "a_dt_pth = aim_pths_c\n",
        "# a_dt_pth = aim_pths[0]\n",
        "# a_dt_pth = aim_pths[-1]\n",
        "\n",
        "# b_dt_pth = aim_pths[1]\n",
        "# b_dt_pth = aim_pths[2] # Ground Truth New\n",
        "b_dt_pth = aim_pths[-1]\n",
        "\n",
        "\n",
        "root = '/content/drive/MyDrive/Colab Notebooks/WBC_DB/'\n",
        "res_c = root + 'Cy/' + pths[aim] + '/'\n",
        "res_mdl_c = root + 'Cy/model/' + pths[aim] + '/'\n",
        "lss_c = root + 'Cy/loss/' + pths[aim] + '/'\n",
        "\n",
        "res_g = root + 'G/' + pths[aim] + '/'\n",
        "res_mdl_g = root + 'G/model/' + pths[aim] + '/'\n",
        "lss_g = root + 'G/loss/' + pths[aim] + '/'\n",
        "\n",
        "a_ge_pth_c = root + 'GeCy/' + pths[aim] + '_A' # دسته A\n",
        "b_ge_pth_c = root + 'GeCy/' + pths[aim] + '_B' # دسته B\n",
        "\n",
        "ge_pth_g = root + 'GeG/' + pths[aim]\n",
        "\n",
        "os.makedirs(res_c, exist_ok=True)\n",
        "os.makedirs(res_mdl_c, exist_ok=True)\n",
        "os.makedirs(lss_c, exist_ok=True)\n",
        "\n",
        "os.makedirs(res_g, exist_ok=True)\n",
        "os.makedirs(res_mdl_g, exist_ok=True)\n",
        "os.makedirs(lss_g, exist_ok=True)\n",
        "\n",
        "os.makedirs(a_ge_pth_c, exist_ok=True)\n",
        "os.makedirs(b_ge_pth_c, exist_ok=True)\n",
        "\n",
        "os.makedirs(ge_pth_g, exist_ok=True)\n",
        "\n",
        "# a_dt_imgs = [os.path.join(a_dt_pth, f) for f in os.listdir(a_dt_pth) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "a_dt_imgs = []\n",
        "for path in a_dt_pth:\n",
        "  a_dt_imgs.extend([os.path.join(path, f) for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "random.shuffle(a_dt_imgs)\n",
        "a_dt_imgs = a_dt_imgs[:300]  # << Your random subset [[1]][[3]] 795  = len Monocyte\n",
        "\n",
        "b_dt_imgs = [os.path.join(b_dt_pth, f) for f in os.listdir(b_dt_pth) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "dt_imgs_raw = a_dt_imgs + b_dt_imgs\n",
        "\n",
        "a_ge_imgs_c = [os.path.join(a_ge_pth_c, f) for f in os.listdir(a_ge_pth_c) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "b_ge_imgs_c = [os.path.join(b_ge_pth_c, f) for f in os.listdir(b_ge_pth_c) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "dt_imgs_c = a_ge_imgs_c + b_ge_imgs_c\n",
        "\n",
        "\n",
        "# dt_imgs = dt_imgs_raw + dt_imgs_c\n",
        "dt_imgs = dt_imgs_c + a_dt_imgs\n",
        "\n",
        "\n",
        "ge_imgs_g = [os.path.join(ge_pth_g, f) for f in os.listdir(ge_pth_g) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "print(f\"A data for {pths[aim]}:\",len(a_dt_imgs),a_dt_imgs)\n",
        "print(f\"B data for {pths[aim]}:\",len(b_dt_imgs),b_dt_imgs)\n",
        "\n",
        "print(f\"Cycle Generated A for {pths[aim]}:\",len(a_ge_imgs_c),a_ge_imgs_c)\n",
        "print(f\"Cycle Generated B for {pths[aim]}:\",len(b_ge_imgs_c),b_ge_imgs_c)\n",
        "print(f\"Cycle Generated B for {pths[aim]}:\",len(b_ge_imgs_c),b_ge_imgs_c)\n",
        "print(f\"All Cycle generated for {pths[aim]}:\",len(dt_imgs_c),dt_imgs_c)\n",
        "print(f\"All Raw data for {pths[aim]}:\",len(dt_imgs_raw),dt_imgs_raw)\n",
        "print(f\"All data for {pths[aim]}:\",len(dt_imgs),dt_imgs)\n",
        "print(f\"All GAN Generated  {pths[aim]}:\",len(ge_imgs_g),ge_imgs_g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhY-fqCxWTHP"
      },
      "source": [
        "# Variables for R3GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfBGXjhyXNuC"
      },
      "outputs": [],
      "source": [
        "num_or = 1000 #1000\n",
        "num_a =  300 #300\n",
        "num_b = 700 #700\n",
        "bs_c = '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/'\n",
        "dt_c = [bs_c+'Train/',bs_c+'Test/']\n",
        "\n",
        "pths=['Basophil','Eosinophil','Lymphocyte','Monocyte','Neutrophil']\n",
        "# Faghat roo Basophil javab dade\n",
        "aim = 4 # 'Basophil 0 ok','Eosinophil 1 ok','Lymphocyte 2 ok az 10-30','Monocyte 3 400 epoch az 300 be bad','Neutrophil 4 30 va 40 khoobe baghie ok nist'\n",
        "aim_pths_c = [d + pths[aim] + '/' for d in dt_c]  # << Corrected line [[1]][[2]]\n",
        "\n",
        "or_dt_pth = aim_pths_c\n",
        "\n",
        "\n",
        "\n",
        "root = '/content/drive/MyDrive/Colab Notebooks/WBC_DB/'\n",
        "\n",
        "\n",
        "\n",
        "res_g = root + 'G/' + pths[aim] + '/'\n",
        "res_mdl_g = root + 'G/model/' + pths[aim] + '/'\n",
        "lss_g = root + 'G/loss/' + pths[aim] + '/'\n",
        "\n",
        "a_ge_pth_c = root + 'GeCy/' + pths[aim] + '_A' # دسته A\n",
        "b_ge_pth_c = root + 'GeCy/' + pths[aim] + '_B' # دسته B\n",
        "\n",
        "\n",
        "ge_pth_g = root + 'GeG/' + pths[aim]\n",
        "\n",
        "os.makedirs(root, exist_ok=True)\n",
        "os.makedirs(res_g, exist_ok=True)\n",
        "os.makedirs(res_mdl_g, exist_ok=True)\n",
        "os.makedirs(lss_g, exist_ok=True)\n",
        "\n",
        "os.makedirs(a_ge_pth_c, exist_ok=True)\n",
        "os.makedirs(b_ge_pth_c, exist_ok=True)\n",
        "\n",
        "os.makedirs(ge_pth_g, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "or_imgs = []\n",
        "for path in or_dt_pth:\n",
        "  or_imgs.extend([os.path.join(path, f) for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "random.shuffle(or_imgs)\n",
        "or_imgs = or_imgs[:num_or]  # << Your random subset [[1]][[3]] 795  = len Monocyte\n",
        "\n",
        "a_ge_imgs_c = [os.path.join(a_ge_pth_c, f) for f in os.listdir(a_ge_pth_c) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "random.shuffle(a_ge_imgs_c)\n",
        "a_ge_imgs_c = a_ge_imgs_c[:num_a]  # << Your random subset [[1]][[3]] 795  = len Monocyte\n",
        "\n",
        "b_ge_imgs_c = [os.path.join(b_ge_pth_c, f) for f in os.listdir(b_ge_pth_c) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "random.shuffle(b_ge_imgs_c)\n",
        "b_ge_imgs_c = b_ge_imgs_c[:num_b]  # << Your random subset [[1]][[3]] 795  = len Monocyte\n",
        "\n",
        "dt_imgs = or_imgs + a_ge_imgs_c + b_ge_imgs_c\n",
        "\n",
        "\n",
        "ge_imgs_g = [os.path.join(ge_pth_g, f) for f in os.listdir(ge_pth_g) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "dt_prpsd = or_imgs + ge_imgs_g\n",
        "\n",
        "\n",
        "print(f\"Orginal Data {pths[aim]}:\",len(or_imgs),or_imgs)\n",
        "\n",
        "print(f\"Cycle Data A {pths[aim]}:\",len(a_ge_imgs_c),a_ge_imgs_c)\n",
        "print(f\"Cycle Data B {pths[aim]}:\",len(b_ge_imgs_c),b_ge_imgs_c)\n",
        "\n",
        "print(f\"All GAN DATA  {pths[aim]}:\",len(dt_imgs),dt_imgs)\n",
        "\n",
        "print(f\"All GAN Generated  {pths[aim]}:\",len(ge_imgs_g),ge_imgs_g)\n",
        "\n",
        "print(f\"Data Proposed  {pths[aim]}:\",len(dt_prpsd),dt_prpsd)\n",
        "\n",
        "\n",
        "# GEG+RAW=PROPOSED-DT -->> Basophil: 1100+301=1401, Eosinophil: 595+1000=1595, Lymphocyte: 975+1000=1975, Monocyte: 670+795=1465, Neutrophil: 850+1000=1850"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHsvop-5wb67"
      },
      "source": [
        "## Train on CPU for temperory testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IAZgL20qg-X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# results_path = res_g\n",
        "\n",
        "\n",
        "# تنظیمات اولیه\n",
        "latent_dim = 4 #128\n",
        "image_size = 256  # اندازه تصویر 256x256 256\n",
        "batch_size = 1   # 8 # کاهش batch size برای تصاویر بزرگتر\n",
        "num_epochs = 5   # افزایش تعداد ایپوک برای آموزش بهتر\n",
        "\n",
        "intrvl = 2\n",
        "\n",
        "# Create dataset from paths\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(dt_imgs)\n",
        "\n",
        "# Define preprocessing function (ensure it returns a tensor with known shape)\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=3, dtype=tf.float32)  # << Read as RGB [[1]]\n",
        "    img.set_shape([image_size, image_size, 3])  # << Fixed shape (256x256x3) [[2]]\n",
        "    img = tf.image.resize(img, [image_size, image_size])  # << Resize ensures consistent dimensions [[2]]\n",
        "    img = (img / 127.5) - 1.0  # << Normalize to [-1, 1] [[5]]\n",
        "    return img\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    load_and_preprocess_image,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").batch(batch_size).shuffle(buffer_size=1000)  # << Final dataset setup [[1]][[2]]\n",
        "\n",
        "def build_generator(latent_dim, image_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    init_size = image_size // 32\n",
        "    model.add(layers.Dense(init_size * init_size * 512, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((init_size, init_size, 512)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    return model\n",
        "\n",
        "# تعریف تشخیص‌گر (Discriminator) برای تصاویر 256x256\n",
        "def build_discriminator(image_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=[image_size, image_size, 3]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Define generator and discriminator\n",
        "generator = build_generator(latent_dim, image_size)\n",
        "discriminator = build_discriminator(image_size)\n",
        "\n",
        "# تابع از دست رساندن\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# تعریف تابع از دست رساندن برای مولد\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# تعریف تابع از دست رساندن برای تشخیص‌گر\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "# بهینه‌سازی\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "\n",
        "# Training loop (ensure shapes are correct before training)\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# آموزش مدل\n",
        "def train(dataset, epochs):\n",
        "    # ایجاد فایل CSV اگر وجود ندارد\n",
        "    csv_file = lss_g + pths[-1] + '_cygan_loss.csv'\n",
        "    if not os.path.exists(csv_file):\n",
        "        with open(csv_file, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\", \"Generator Loss\", \"Discriminator Loss\"])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for image_batch in dataset:\n",
        "          gen_loss, disc_loss = train_step(image_batch)\n",
        "\n",
        "      with open(csv_file, mode='a', newline='') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([epoch + 1, gen_loss.numpy(), disc_loss.numpy()])\n",
        "      print(f\"Epoch {epoch}/{epochs}, Generator Loss: {gen_loss.numpy():.4f}, Discriminator Loss: {disc_loss.numpy():.4f}\")\n",
        "      generate_and_save_images(generator, epoch + 1, seed,sv=False)\n",
        "      # هر 20 تا در پنجره پایین نمایش میده\n",
        "      # if epoch % intrvl == 0:\n",
        "      #       # نمایش و ذخیره تصاویر تولید شده\n",
        "      #       generate_and_save_images(generator, epoch + 1, seed,sv=True)\n",
        "\n",
        "# تابع نمایش و ذخیره تصاویر رنگی\n",
        "def generate_and_save_images(model, epoch, test_input,sv=False):\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(8, 8), dpi = 72)\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        img = (predictions[i] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    if sv:\n",
        "      save_path = os.path.join(res_g, f'epc_{epoch:04d}.png')\n",
        "      plt.savefig(save_path)\n",
        "    plt.close(fig)  # بستن شکل برای جلوگیری از مصرف حافظه زیاد\n",
        "\n",
        "# تعریف ورودی ثابت برای نمایش تصاویر\n",
        "seed = tf.random.normal([16, latent_dim])\n",
        "\n",
        "# شروع آموزش\n",
        "# train(train_dataset, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "821Qq-L-7y93"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "train(train_dataset, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAi84nYiwgE1"
      },
      "source": [
        "## Train on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcK7JHGPwiMi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# === Initial Setup ===\n",
        "image_size = 256\n",
        "latent_dim = 100  # Fixed latent dimension [[1]]\n",
        "batch_size = 2\n",
        "num_epochs = 40\n",
        "intrvl = 5\n",
        "lr = 0.00005 #0.0001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "csv_file = Path(lss_g + pths[aim] + '_g_lss.csv')\n",
        "csv_file.touch(exist_ok=True)\n",
        "\n",
        "# === Dataset Creation ===\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1,1] [[5]]\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        return self.transform(img)\n",
        "\n",
        "train_dataset = ImageDataset(dt_imgs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Verify dataset shape\n",
        "for batch in train_loader:\n",
        "    assert batch.shape == (batch_size, 3, image_size, image_size), f\"Batch shape mismatch: {batch.shape}\"\n",
        "    break\n",
        "\n",
        "# === Generator Architecture ===\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, image_size):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # Initial linear projection\n",
        "        self.initial_linear = nn.Linear(latent_dim, 512 * 8 * 8)  # (batch, 512*8*8)\n",
        "\n",
        "        # Reshape to (batch, 512, 8, 8)\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 16x16\n",
        "\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 32x32\n",
        "\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 64x64\n",
        "\n",
        "        self.up4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 128x128\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )  # → 256x256\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Map noise to linear space\n",
        "        x = self.initial_linear(x)\n",
        "        # Reshape to 512x8x8 [[1]]\n",
        "        x = x.view(-1, 512, 8, 8)  # << Critical reshape [[1]]\n",
        "\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        x = self.up3(x)\n",
        "        x = self.up4(x)\n",
        "        return self.final(x)\n",
        "\n",
        "# === Discriminator Architecture ===\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_size):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),  # Global pooling [[5]]\n",
        "            nn.Flatten(),  # (batch, 512)\n",
        "            nn.Linear(512, 1)  # Scalar output [[5]]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator(latent_dim, image_size).to(device)\n",
        "discriminator = Discriminator(image_size).to(device)\n",
        "\n",
        "# Define loss and optimizers\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)  # Binary cross entropy [[5]]\n",
        "\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Custom weight initialization\n",
        "def weights_init(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
        "        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)  # << Replicating TF initialization [[3]]\n",
        "\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# === Loss Functions ===\n",
        "def generator_loss(fake_output):\n",
        "    return criterion(fake_output, torch.ones_like(fake_output).to(device))\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = criterion(real_output, torch.ones_like(real_output).to(device))\n",
        "    fake_loss = criterion(fake_output, torch.zeros_like(fake_output).to(device))\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "# === Training Loop ===\n",
        "def train_step(images):\n",
        "    valid = torch.ones(images.size(0), 1, device=device)\n",
        "    fake = torch.zeros(images.size(0), 1, device=device)\n",
        "\n",
        "    # Train Generator\n",
        "    generator_optimizer.zero_grad()\n",
        "    z = torch.randn(images.size(0), latent_dim, device=device)\n",
        "    generated_images = generator(z)\n",
        "    g_loss = generator_loss(discriminator(generated_images))\n",
        "    g_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    # Train Discriminator\n",
        "    discriminator_optimizer.zero_grad()\n",
        "    real_pred = discriminator(images)\n",
        "    fake_pred = discriminator(generated_images.detach())\n",
        "    d_loss_real = criterion(real_pred, valid)\n",
        "    d_loss_fake = criterion(fake_pred, fake)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    d_loss.backward()\n",
        "    discriminator_optimizer.step()\n",
        "\n",
        "    return g_loss.item(), d_loss.item()\n",
        "\n",
        "# === Image Generation Function ===\n",
        "# def generate_and_save_images(model, epoch, test_input, sv=False):\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         predictions = model(test_input).cpu()\n",
        "#     if sv:\n",
        "#       d=300\n",
        "#     else:\n",
        "#       d=36\n",
        "#     fig = plt.figure(figsize=(8, 8), dpi=d)\n",
        "#     for i in range(predictions.shape[0]):\n",
        "#         plt.subplot(4, 4, i+1)\n",
        "#         img = ((predictions[i].numpy().transpose(1, 2, 0) + 1) / 2 * 255).astype(np.uint8)\n",
        "#         plt.imshow(img)\n",
        "#         plt.axis('off')\n",
        "\n",
        "#     if sv:\n",
        "#         plt.savefig(os.path.join(res_g, f'epc_{epoch:04d}.png'))\n",
        "#     plt.show()\n",
        "#     plt.close(fig)\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, sv=False):\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    num_samples=16\n",
        "    # Generate new random noise each time\n",
        "    noise = torch.randn(num_samples, latent_dim, device=device)  # << Random seed every call [[1]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_images = model(noise).cpu()  # Generate and move to CPU [[2]]\n",
        "\n",
        "    d = 36\n",
        "    if sv:\n",
        "      d = 300\n",
        "    # Prepare to show images\n",
        "    fig = plt.figure(figsize=(8, 8), dpi=d)\n",
        "    rows = cols = int(np.ceil(np.sqrt(num_samples)))  # Dynamic layout\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.axis('off')\n",
        "        img = ((generated_images[i] * 0.5 + 0.5) * 255).clamp(0, 255).permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "        plt.imshow(img)\n",
        "        if sv:\n",
        "          plt.savefig(os.path.join(res_g, f'epc_{epoch:04d}.png'),bbox_inches='tight')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "# === Start Training ===\n",
        "def train(dataset, epochs):\n",
        "    flg = True\n",
        "    with open(csv_file, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Epoch\", \"Generator Loss\", \"Discriminator Loss\"])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_images in dataset:\n",
        "            real_images = real_images.to(device)\n",
        "            gen_loss, disc_loss = train_step(real_images)\n",
        "        with open(csv_file, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch+1, gen_loss, disc_loss])\n",
        "\n",
        "        if (epoch + 1) % intrvl == 0:\n",
        "            flg = False\n",
        "            generate_and_save_images(generator, epoch+1, sv=True)\n",
        "            torch.save(generator.state_dict(), f\"{res_mdl_g}e_{epoch+1}.pth\")\n",
        "\n",
        "        else:\n",
        "            flg = True\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"  Generator Loss: {gen_loss:.4f}\")\n",
        "        print(f\"  Discriminator Loss: {disc_loss:.4f}\")\n",
        "        if flg:\n",
        "          generate_and_save_images(generator, epoch+1, sv=False)\n",
        "\n",
        "# Initialize seed\n",
        "# seed = torch.randn(16, latent_dim, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMDP78Lehy8x"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(f\"Using {'GPU' if device.type == 'cuda' else 'CPU'} acceleration\")\n",
        "print(pths[aim])\n",
        "print('batch_size: ', batch_size)\n",
        "print('num_epochs: ', num_epochs)\n",
        "print('lr: ', lr)\n",
        "print('image_size: ', image_size)\n",
        "print('intrvl: ', intrvl)\n",
        "train(train_loader, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12ff6wMDH32X"
      },
      "source": [
        "## load model in order to show and generate new images from GANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VESUKG82Pffi"
      },
      "outputs": [],
      "source": [
        "def generate_timestamp_decimal():\n",
        "    current_time = datetime.datetime.now()  # [[2]]\n",
        "    date_part = current_time.strftime(\"%d-%m-%y\")  # Day-Month-Last two digits of year [[3]]\n",
        "    time_part = current_time.strftime(\"%H-%M-%S\")  # Hour:Minute:Second [[2]]\n",
        "    decimal_num = int(round(random.uniform(0, 1) * 1000))  # << Key adjustment [[5]][[9]]\n",
        "    return f\"{date_part}-{time_part}-{decimal_num}\"\n",
        "\n",
        "result = generate_timestamp_decimal()\n",
        "print(result)  # Output: \"15-04-25 14:30:45 0.123\" [[1]][[2]][[3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4IUU3LbId-X"
      },
      "outputs": [],
      "source": [
        "# New method for generating random images from saved model\n",
        "def generate_random_images(model_path, num_images=16, sv=False,sh=False,o_d=None,ep=0):\n",
        "\n",
        "    # Load model architecture\n",
        "    gen = Generator(latent_dim,image_size).to(device)\n",
        "\n",
        "    # Load weights\n",
        "    try:\n",
        "        gen.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        print(f\"Model loaded from {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    gen.eval()\n",
        "\n",
        "    # Generate random noise\n",
        "    noise = torch.randn(num_images, latent_dim, device=device)\n",
        "\n",
        "    # Generate images\n",
        "    with torch.no_grad():\n",
        "        fake_images = gen(noise)\n",
        "\n",
        "    # Create figure for visualization\n",
        "    if sh:\n",
        "      fig = plt.figure(figsize=(8, 8))\n",
        "      columns = min(4, num_images)\n",
        "      rows = (num_images + columns - 1) // columns\n",
        "\n",
        "      for i in range(num_images):\n",
        "          plt.subplot(rows, columns, i+1)\n",
        "          img = ((fake_images[i].cpu() * 0.5 + 0.5) * 255).clamp(0, 255).permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "          plt.imshow(img)\n",
        "          plt.axis('off')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      plt.close(fig)\n",
        "\n",
        "\n",
        "    # Save individual images if output_dir specified\n",
        "    if sv:\n",
        "      for i in range(num_images):\n",
        "          img = ((fake_images[i].cpu() * 0.5 + 0.5) * 255).clamp(0, 255).permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "          Image.fromarray(img).save(f\"{o_d}/geg_epc_{str(ep)}_{i:03d}_{generate_timestamp_decimal()}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaq-EP2KPvPd"
      },
      "outputs": [],
      "source": [
        "e = 70 # 10 20 30 40 50 60 70\n",
        "latest_model = f\"{res_mdl_g}e_{e}.pth\"\n",
        "# generate_random_images(latest_model, num_images=20, sv=False, sh=True, o_d=ge_pth_g,ep=e)\n",
        "# generate_random_images(latest_model, num_images=250, sv=True, sh=False, o_d=ge_pth_g,ep=e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na2qw00SqAhD"
      },
      "source": [
        "# ECC GAN implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QQcVQTT4t6P"
      },
      "source": [
        "## Device Varibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmIML1yT4vwk"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# image_size = 256  # ابعاد تصویر\n",
        "# batch_size = 1\n",
        "# num_epochs = 20\n",
        "# # dim = 2048\n",
        "# intrvl = 4 # میگیم هر چند اپوک مد رو ذخیره کنه\n",
        "# lr = 0.0001 #0.0001\n",
        "# lambda_cycle = 10.0 #10\n",
        "# lambda_identity = 0.5 #0.5\n",
        "\n",
        "image_size = 256  # ابعاد تصویر\n",
        "intrvl = 4 # میگیم هر چند اپوک مد رو ذخیره کنه\n",
        "batch_size = 8 #بالاتر از ۱۶ نمیشه\n",
        "num_epochs = 16\n",
        "lr = 0.0001 #0.0001\n",
        "lambda_cycle = 10 #10\n",
        "lambda_identity = 0.25 #0.5\n",
        "\n",
        "# if aim == 0:\n",
        "#   batch_size = 8\n",
        "#   num_epochs = 100\n",
        "#   lambda_cycle = 20 #10\n",
        "#   lambda_identity = 0.125 #0.5\n",
        "#   lr = 0.0001 #0.0001\n",
        "#   lambda_cycle = 10.0 #10\n",
        "#   lambda_identity = 0.5 #0.5\n",
        "\n",
        "print(pths[aim])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uMPfftD4z_A"
      },
      "source": [
        "## Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyhQ3dIu42Bc"
      },
      "outputs": [],
      "source": [
        "# تعریف تبدیل تصویر\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # نرمالایز به [-1,1] [[5]]\n",
        "])\n",
        "\n",
        "# کلاس داده سیت برای پیش‌پردازش تصاویر\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, paths_A, paths_B):\n",
        "        self.paths_A = paths_A\n",
        "        self.paths_B = paths_B\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_A = Image.open(self.paths_A[index % len(self.paths_A)]).convert(\"RGB\")\n",
        "        img_B = Image.open(self.paths_B[index % len(self.paths_B)]).convert(\"RGB\")\n",
        "        return self.transform(img_A), self.transform(img_B)\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.paths_A), len(self.paths_B))\n",
        "\n",
        "# ساخت داده سیت\n",
        "def create_dataset(paths_A, paths_B):\n",
        "    dataset = ImageDataset(paths_A, paths_B)\n",
        "    return torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "# Residual Block برای مولد\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        return out + identity  # [[7]]\n",
        "\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 init_filters=64,  # لایه اول Downsampling [[1]]\n",
        "                 mid_filters=128,  # لایه دوم Downsampling [[1]]\n",
        "                 res_filters=256,  # لایه Residual [[1]]\n",
        "                 num_residuals=9  # تعداد Blockهای Residual [[2]]\n",
        "                ):\n",
        "        super(Generator, self).__init__()  # << استفاده صحیح از super() [[3]][[4]]\n",
        "\n",
        "        # Downsampling\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.Conv2d(3, init_filters, kernel_size=7, padding=3),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.Conv2d(init_filters, mid_filters, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(mid_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.Conv2d(mid_filters, res_filters, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(res_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Residual Blocks\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(res_filters) for _ in range(num_residuals)]\n",
        "        )\n",
        "\n",
        "        # Upsampling\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(res_filters, mid_filters, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(mid_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(mid_filters, init_filters, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.BatchNorm2d(init_filters),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.final = nn.Sequential(\n",
        "            nn.Conv2d(init_filters, 3, kernel_size=7, padding=3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.down1(x)\n",
        "        x = self.down2(x)\n",
        "        x = self.down3(x)\n",
        "        x = self.res_blocks(x)\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        return self.final(x)\n",
        "\n",
        "\n",
        "# مولد ها\n",
        "generator_AtoB = Generator(\n",
        "    init_filters=32,    # کاهش اولین لایه Downsampling [[1]]\n",
        "    mid_filters=64,     # کاهش لایه دوم Downsampling [[1]]\n",
        "    res_filters=128,    # کاهش تعداد فیلترهای Residual [[1]]\n",
        "    num_residuals=6     # کاهش تعداد Blockهای Residual [[2]]\n",
        ")\n",
        "generator_BtoA = Generator(\n",
        "    init_filters=32,\n",
        "    mid_filters=64,\n",
        "    res_filters=128,\n",
        "    num_residuals=6\n",
        ")\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels=3,\n",
        "                 filters=[64, 128, 256],  # لایههای کانولوشنی [[1]]\n",
        "                 kernel_size=4,\n",
        "                 stride=2\n",
        "                ):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        current_filters = in_channels\n",
        "        for filt in filters:\n",
        "            layers.append(\n",
        "                nn.Conv2d(current_filters, filt, kernel_size, stride, padding=1)\n",
        "            )\n",
        "            if filt != filters[-1]:  # برای آخرین لایه BatchNorm نیاز نیست\n",
        "                layers.append(nn.BatchNorm2d(filt))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            current_filters = filt\n",
        "\n",
        "        # لایه آخر\n",
        "        layers.append(nn.Conv2d(current_filters, 1, kernel_size, stride=1, padding=1))\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# تشخیصگرها\n",
        "discriminator_A = Discriminator(\n",
        "    filters=[64, 128, 128]  # کاهش تعداد فیلترهای لایه سوم [[1]]\n",
        ")\n",
        "discriminator_B = Discriminator(\n",
        "    filters=[64, 128, 128]\n",
        ")\n",
        "\n",
        "\n",
        "# تابع هزینه\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "criterion_identity = nn.L1Loss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# بهینه‌سازی\n",
        "optimizer_G = optim.Adam(\n",
        "    list(generator_AtoB.parameters()) + list(generator_BtoA.parameters()),\n",
        "    lr=lr,\n",
        "    betas=(0.5, 0.999)\n",
        ")\n",
        "optimizer_D_A = optim.Adam(discriminator_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = optim.Adam(discriminator_B.parameters(), lr=lr, betas=(0.5, 0.999))  # << اصلاح اینجا\n",
        "\n",
        "# تابع نمایش\n",
        "def generate_and_save_images(epoch, test_A, test_B):\n",
        "    generator_AtoB.eval()\n",
        "    generator_BtoA.eval()\n",
        "    # Random indices within batch sizes [[7]][[10]]\n",
        "    batch_size_A = test_A.size(0)\n",
        "    batch_size_B = test_B.size(0)\n",
        "    idx_A = random.randint(0, batch_size_A - 1)\n",
        "    idx_B = random.randint(0, batch_size_B - 1)\n",
        "    # real_A_name = os.path.basename(a_dt_imgs[idx_A])\n",
        "    # real_B_name = os.path.basename(b_dt_imgs[idx_B])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_B = generator_AtoB(test_A)\n",
        "        fake_A = generator_BtoA(test_B)\n",
        "        recon_A = generator_BtoA(fake_B)\n",
        "        recon_B = generator_AtoB(fake_A)\n",
        "    fntsz = 36\n",
        "    fntwt = 40\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    plt.subplot(2,3,1)\n",
        "    plt.imshow((test_A[idx_A].cpu().numpy().transpose(1,2,0)+1)/2)\n",
        "    # plt.title(real_A_name, fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.title(\"Real A\", fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.subplot(2,3,2)\n",
        "    plt.imshow((fake_B[idx_A].cpu().numpy().transpose(1,2,0)+1)/2)\n",
        "    plt.title(\"Fake B\", fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.subplot(2,3,3)\n",
        "    plt.imshow((recon_A[idx_A].cpu().numpy().transpose(1,2,0)+1)/2)\n",
        "    plt.title(\"Reconstructed A\", fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.subplot(2,3,4)\n",
        "    plt.imshow((test_B[idx_B].cpu().numpy().transpose(1,2,0)+1)/2)\n",
        "    # plt.title(real_B_name, fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.title(\"Real B\", fontsize=fntsz, fontweight=fntwt)\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.subplot(2,3,5)\n",
        "    plt.imshow((fake_A[idx_B].cpu().numpy().transpose(1,2,0)+1)/2)\n",
        "    plt.title(\"Fake A\", fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.subplot(2,3,6)\n",
        "    plt.imshow((recon_B[idx_B].cpu().numpy().transpose(1,2,0)+1)/2)\n",
        "    plt.title(\"Reconstructed B\", fontsize=fntsz, fontweight=fntwt)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(f\"{res_c}/e_{epoch}.png\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# حلقه آموزش\n",
        "def train(dataset, epochs):\n",
        "\n",
        "    generator_AtoB.to(device)\n",
        "    generator_BtoA.to(device)\n",
        "    discriminator_A.to(device)\n",
        "    discriminator_B.to(device)\n",
        "    # Before training starts (initialize CSV):\n",
        "    csv_file = lss_c + pths[-1] + '_cygan_loss.csv'\n",
        "    with open(csv_file, 'w', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(['Epoch', 'Generator Loss', 'Discriminator A Loss', 'Discriminator B Loss'])  # [[2]][[3]]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (real_A, real_B) in enumerate(dataset):\n",
        "            real_A = real_A.to(device)\n",
        "            real_B = real_B.to(device)\n",
        "\n",
        "            # آموزش مولد\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # تولید تصاویر\n",
        "            fake_B = generator_AtoB(real_A)\n",
        "            fake_A = generator_BtoA(real_B)\n",
        "\n",
        "            # بازسازی\n",
        "            recon_A = generator_BtoA(fake_B)\n",
        "            recon_B = generator_AtoB(fake_A)\n",
        "\n",
        "            # هذلولی\n",
        "            identity_A = generator_BtoA(real_A)\n",
        "            identity_B = generator_AtoB(real_B)\n",
        "\n",
        "            # Loss های GAN\n",
        "            loss_GAN_A = criterion_GAN(discriminator_B(fake_B), torch.ones_like(discriminator_B(fake_B)))  # [[5]]\n",
        "            loss_GAN_B = criterion_GAN(discriminator_A(fake_A), torch.ones_like(discriminator_A(fake_A)))\n",
        "\n",
        "            # Loss سیکل\n",
        "            loss_cycle = criterion_cycle(recon_A, real_A) + criterion_cycle(recon_B, real_B)\n",
        "\n",
        "            # Loss هذلولی\n",
        "            loss_identity = criterion_identity(identity_A, real_A) + criterion_identity(identity_B, real_B)\n",
        "\n",
        "            # Loss مجموع\n",
        "            total_loss_G = loss_GAN_A + loss_GAN_B + lambda_cycle * loss_cycle + lambda_identity * loss_identity\n",
        "            total_loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # آموزش تشخیصگر A\n",
        "            optimizer_D_A.zero_grad()\n",
        "            pred_real_A = discriminator_A(real_A)\n",
        "            pred_fake_A = discriminator_A(fake_A.detach())\n",
        "\n",
        "            loss_D_A = criterion_GAN(pred_real_A, torch.ones_like(pred_real_A)) + \\\n",
        "                      criterion_GAN(pred_fake_A, torch.zeros_like(pred_fake_A))\n",
        "            loss_D_A.backward()\n",
        "            optimizer_D_A.step()\n",
        "\n",
        "            # آموزش تشخیصگر B\n",
        "            optimizer_D_B.zero_grad()\n",
        "            pred_real_B = discriminator_B(real_B)\n",
        "            pred_fake_B = discriminator_B(fake_B.detach())\n",
        "\n",
        "            loss_D_B = criterion_GAN(pred_real_B, torch.ones_like(pred_real_B)) + \\\n",
        "                      criterion_GAN(pred_fake_B, torch.zeros_like(pred_fake_B))\n",
        "            loss_D_B.backward()\n",
        "            optimizer_D_B.step()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}:\")\n",
        "        print(f\"  Generator Loss: {total_loss_G.item():.4f}\")\n",
        "        print(f\"  Discriminator A Loss: {loss_D_A.item():.4f} | Discriminator B Loss: {loss_D_B.item():.4f}\")\n",
        "        # save css\n",
        "        with open(csv_file, 'a', newline='') as f:\n",
        "          writer = csv.writer(f)\n",
        "          writer.writerow([\n",
        "          epoch+1,\n",
        "          f\"{total_loss_G.item():.4f}\",\n",
        "          f\"{loss_D_A.item():.4f}\",\n",
        "          f\"{loss_D_B.item():.4f}\"\n",
        "        ])\n",
        "\n",
        "        if (epoch + 1) % intrvl == 0:\n",
        "            torch.save(generator_AtoB.state_dict(), f\"{res_mdl_c}/generator_AtoB_epoch_{epoch+1}.pth\")\n",
        "            torch.save(generator_BtoA.state_dict(), f\"{res_mdl_c}/generator_BtoA_epoch_{epoch+1}.pth\")\n",
        "        # تصاویر نمونه برای نمایش غیر تکراری\n",
        "        random_batch = next(iter(dataset))\n",
        "        test_A = random_batch[0].to(device)\n",
        "        test_B = random_batch[1].to(device)\n",
        "\n",
        "        generate_and_save_images(epoch+1, test_A, test_B)\n",
        "\n",
        "root = '/content/drive/MyDrive/Colab Notebooks/WBC_DB/'\n",
        "res_c = root + 'Cy/' + pths[aim] + '/'\n",
        "res_mdl_c = root + 'Cy/model/' + pths[aim] + '/'\n",
        "lss_c = root + 'Cy/loss/' + pths[aim] + '/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX5qgYcb5Hzv"
      },
      "source": [
        "## Start Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "poshB1hX5KUx"
      },
      "outputs": [],
      "source": [
        "dataset = create_dataset(a_dt_imgs, b_dt_imgs)\n",
        "print(pths[aim])\n",
        "print('batch_size: ', batch_size)\n",
        "print('num_epochs: ', num_epochs)\n",
        "print('lambda_cycle: ', lambda_cycle)\n",
        "print('lambda_identity: ', lambda_identity)\n",
        "print('lr: ', lr)\n",
        "print('image_size: ', image_size)\n",
        "print('intrvl: ', intrvl)\n",
        "\n",
        "# train(dataset, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyWLwCUBTKNq"
      },
      "source": [
        "## naming new images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLuW_wXDTdjC"
      },
      "outputs": [],
      "source": [
        "def generate_timestamp_decimal():\n",
        "    current_time = datetime.datetime.now()  # [[2]]\n",
        "    date_part = current_time.strftime(\"%d-%m-%y\")  # Day-Month-Last two digits of year [[3]]\n",
        "    time_part = current_time.strftime(\"%H-%M-%S\")  # Hour:Minute:Second [[2]]\n",
        "    decimal_num = int(round(random.uniform(0, 1) * 1000))  # << Key adjustment [[5]][[9]]\n",
        "\n",
        "\n",
        "    return f\"{date_part}-{time_part}-{decimal_num}\"\n",
        "\n",
        "result = generate_timestamp_decimal()\n",
        "print(result)  # Output: \"15-04-25 14:30:45 0.123\" [[1]][[2]][[3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVKayJfBUSyz"
      },
      "outputs": [],
      "source": [
        "cnt_g_img = 50 # 4 8 12 16 ...100\n",
        "mdl_ep = 100 # 4 8 12 16 ...100\n",
        "print(pths[aim])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy0pEreW-ap_"
      },
      "source": [
        "## Generate new images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEd8-cL_-71n"
      },
      "outputs": [],
      "source": [
        "def generate_show_save_images(impths, generator, test_images, epoch, output_dir='', save=False,filter_bw=True):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(test_images.to(device))\n",
        "\n",
        "    valid_images = []\n",
        "    for img_tensor in fake_images:\n",
        "        img = ((img_tensor.cpu().numpy().transpose(1,2,0) + 1) * 127.5).astype(np.uint8)\n",
        "\n",
        "        # Filter logic\n",
        "        black_mask = np.all(img < 20, axis=-1)\n",
        "        black_percent = (np.sum(black_mask) / img.size) * 100\n",
        "        gray_mask = np.var(img, axis=-1) < 30\n",
        "        gray_percent = (np.sum(gray_mask) / img.size) * 100\n",
        "        if filter_bw:\n",
        "          if black_percent <= 10 and gray_percent <= 10:\n",
        "              valid_images.append((img, black_percent, gray_percent))\n",
        "        else:\n",
        "              valid_images.append((img, black_percent, gray_percent))\n",
        "\n",
        "\n",
        "    # Early exit if no valid images\n",
        "    if not valid_images:\n",
        "        print(\"No valid images to display.\")\n",
        "        return\n",
        "\n",
        "    # Calculate layout\n",
        "    cols = int(np.ceil(np.sqrt(len(valid_images))))\n",
        "    rows = int(np.ceil(len(valid_images) / cols))\n",
        "\n",
        "    # Create figure with correct dimensions\n",
        "    fig = plt.figure(figsize=(cols*2, rows*2),dpi=300)\n",
        "    b = 0\n",
        "    # Plot valid images\n",
        "    for i, (img, _, _) in enumerate(valid_images):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img)\n",
        "        filename = impths[b].split('/')[-1]  # Use os.path.basename(img_path) for cross-platform\n",
        "        plt.title(f\"{i}  {filename}\", fontsize=4)\n",
        "        b = b+1\n",
        "        plt.axis('off')\n",
        "        if save:\n",
        "          Image.fromarray(img).save(os.path.join(output_dir, f\"{i}_epoch_{epoch}_{generate_timestamp_decimal()}.png\"))  # << ذخیره سازی [[7]]\n",
        "\n",
        "\n",
        "    # Save and show\n",
        "    # plt.savefig(os.path.join(output_dir, f\"filtered_epoch_{epoch}.png\"))\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YuQFYEiD_E-O"
      },
      "outputs": [],
      "source": [
        "generator_AtoB = Generator(\n",
        "    init_filters=32,    # کاهش اولین لایه Downsampling [[1]]\n",
        "    mid_filters=64,     # کاهش لایه دوم Downsampling [[1]]\n",
        "    res_filters=128,    # کاهش تعداد فیلترهای Residual [[1]]\n",
        "    num_residuals=6     # کاهش تعداد Blockهای Residual [[2]]\n",
        ")\n",
        "generator_AtoB.load_state_dict(torch.load(res_mdl+\"generator_AtoB_epoch_\"+ str(mdl_ep)+\".pth\",map_location=device))\n",
        "generator_AtoB.to(device).eval()\n",
        "# random.shuffle(a_imgs)\n",
        "# test_A_paths = a_imgs[:cnt_g_img]\n",
        "\n",
        "random.shuffle(a_dt_imgs)\n",
        "test_A_paths = a_dt_imgs[:cnt_g_img]\n",
        "test_A = []\n",
        "for path in test_A_paths:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "    test_A.append(img)\n",
        "test_A = torch.cat(test_A, dim=0)  # [[9]]\n",
        "\n",
        "# ساخت تصاویر\n",
        "generate_show_save_images(\n",
        "    impths=test_A_paths,\n",
        "    generator=generator_AtoB,\n",
        "    test_images=test_A,\n",
        "    epoch=mdl_ep,\n",
        "    output_dir=a_ge_pth,\n",
        "    filter_bw=False\n",
        "    # save=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viaRN_1kS6o_"
      },
      "source": [
        "## reconstrcture images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9q0zxAETEmi"
      },
      "outputs": [],
      "source": [
        "def generate_show_save_images(\n",
        "    impths,\n",
        "    generator_a2b,\n",
        "    generator_b2a,\n",
        "    test_images,\n",
        "    epoch,\n",
        "    output_dir_a='',\n",
        "    output_dir_b='',\n",
        "    save=False,\n",
        "    filter_bw=True,\n",
        "    show=False\n",
        "):\n",
        "    def gr(fake):\n",
        "        # Calculate layout: 2 columns (fake and recon), rows based on valid count\n",
        "\n",
        "        saturation_threshold = 127  # Adjust this to define \"gray\" (lower = more tolerance) [[1]]\n",
        "        min_value = 10  #50           # Mid-intensity range (50-200) [[2]]\n",
        "        max_value = 60 #200\n",
        "        pil_img = Image.fromarray(fake)\n",
        "        hsv_img = pil_img.convert(\"HSV\")\n",
        "        hsv_array = np.array(hsv_img)\n",
        "        # === Brighten Gray Pixels ===\n",
        "        gray_mask = hsv_array[..., 1] < saturation_threshold  # Low saturation (gray pixels)\n",
        "        mid_value_mask = (hsv_array[..., 2] > min_value) & (hsv_array[..., 2] < max_value)\n",
        "        combined_mask = gray_mask & mid_value_mask\n",
        "        # Increase Value (brightness) for gray pixels in midtones\n",
        "        hsv_array[..., 2][combined_mask] += 50  # << Adjust this value (e.g., 50 → 100 for stronger brightening) [[3]]\n",
        "        hsv_array[..., 2] = np.clip(hsv_array[..., 2], 0, 255)  # Clamp values to valid range\n",
        "        # Convert back to RGB and save\n",
        "        enhanced_hsv = Image.fromarray(hsv_array, \"HSV\")\n",
        "        enhanced_rgb = enhanced_hsv.convert(\"RGB\")\n",
        "        return enhanced_rgb\n",
        "\n",
        "\n",
        "\n",
        "    def re(recon): # با افزایش کانتراست و ...و چرخش\n",
        "        pil_recon = Image.fromarray(recon)\n",
        "        # === Random Rotation (Avoid Black Borders) ===\n",
        "        angle = random.choice([90, 180, 270])\n",
        "        rotated = pil_recon.rotate(angle, expand=True)  # << Use expand=True [[1]]\n",
        "        # === Boost Brightness (Random Factor 1.0–2.0) ===\n",
        "        brightness_enhancer = ImageEnhance.Brightness(rotated)\n",
        "        brightness_factor = random.uniform(1.0, 2.0)  # << Increase brightness [[2]]\n",
        "        brightened = brightness_enhancer.enhance(brightness_factor)\n",
        "        # === Enhance Contrast (Random Factor 1.0–2.0) ===\n",
        "        contrast_enhancer = ImageEnhance.Contrast(brightened)\n",
        "        contrast_factor = random.uniform(1.0, 2.0)  # << Sharpen contrast [[3]]\n",
        "        enhanced = contrast_enhancer.enhance(contrast_factor)\n",
        "        return enhanced\n",
        "\n",
        "    generator_a2b.eval()\n",
        "    generator_b2a.eval()\n",
        "    with torch.no_grad():\n",
        "        # Generate fake images\n",
        "        fake_images = generator_a2b(test_images.to(device))\n",
        "        # Generate reconstructed images (B→A)\n",
        "        recon_images = generator_b2a(fake_images)  # << Reconstruction added [[1]]\n",
        "\n",
        "    valid_images = []\n",
        "    for fake_tensor, recon_tensor, img_path in zip(fake_images, recon_images, impths):\n",
        "        # Process fake image\n",
        "        fake = ((fake_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n",
        "        # Process reconstructed image\n",
        "        recon = ((recon_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n",
        "\n",
        "        # Filter fake images (reconstructed images are not filtered)\n",
        "        black_mask = np.all(fake < 20, axis=-1)\n",
        "        black_percent = (np.sum(black_mask) / fake.size) * 100\n",
        "        gray_mask = np.var(fake, axis=-1) < 30\n",
        "        gray_percent = (np.sum(gray_mask) / fake.size) * 100\n",
        "        if filter_bw:\n",
        "            if black_percent <= 10 and gray_percent <= 10:\n",
        "                valid_images.append((fake, recon, img_path))  # << Include recon [[2]]\n",
        "        else:\n",
        "            valid_images.append((fake, recon, img_path))\n",
        "\n",
        "    # Early exit if no valid images\n",
        "    if not valid_images:\n",
        "        print(\"No valid fake images to display.\")\n",
        "        return\n",
        "    num_pairs = len(valid_images)\n",
        "    rows = num_pairs\n",
        "    cols = 2\n",
        "    # Create figure\n",
        "\n",
        "    for i, (fake, recon, img_path) in enumerate(valid_images):\n",
        "        # === Fake Image ===\n",
        "        filename = os.path.basename(img_path)\n",
        "        if show:\n",
        "          fig = plt.figure(figsize=(cols * 4, rows * 4), dpi=72)  # << Adjusted size for 2 columns [[3]]\n",
        "          plt.subplot(rows, cols, 2*i + 1)  # << First column (fake)\n",
        "          plt.title(f\"Fake {i} - {filename}\", fontsize=8)\n",
        "          plt.axis('off')\n",
        "          # plt.imshow(fake)\n",
        "          plt.imshow(gr(fake))\n",
        "          plt.subplot(rows, cols, 2*i + 2)  # << Second column (reconstructed)\n",
        "          plt.title(f\"Recon {i} - {filename}\", fontsize=8)\n",
        "          plt.axis('off')\n",
        "          # plt.imshow(recon)\n",
        "          plt.imshow(re(recon))\n",
        "          plt.show()\n",
        "          plt.tight_layout()\n",
        "          plt.close()\n",
        "        if save:\n",
        "            fake_path = os.path.join(output_dir_a, f\"fk_{i}_e_{epoch}_{generate_timestamp_decimal()}.png\")\n",
        "            # Image.fromarray(fake).save(fake_path)\n",
        "            gr(fake).save(fake_path)  # << Save the modified image [[4]]\n",
        "            recon_path = os.path.join(output_dir_b, f\"rcn_{i}_e_{epoch}_{generate_timestamp_decimal()}.png\")\n",
        "            # Image.fromarray(recon).save(recon_path)\n",
        "            # Convert array to PIL Image\n",
        "            re(recon).save(recon_path)\n",
        "\n",
        "\n",
        "    # Final adjustments\n",
        "    # if save:\n",
        "    #   pass\n",
        "    #     # plt.savefig(os.path.join(output_dir, f\"epoch_{epoch}_comparison.png\"))  # << Save comparison figure [[4]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwCNpSCmb-Ql",
        "outputId": "55c86115-6e7c-418c-8459-100d2e8053e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basophil\n"
          ]
        }
      ],
      "source": [
        "cnt_g_img = 50 # 4 8 12 16 ...100\n",
        "mdl_ep = 100 # 4 8 12 16 ...100\n",
        "print(pths[aim])\n",
        "generator_BtoA = Generator(\n",
        "    init_filters=32,    # کاهش اولین لایه Downsampling [[1]]\n",
        "    mid_filters=64,     # کاهش لایه دوم Downsampling [[1]]\n",
        "    res_filters=128,    # کاهش تعداد فیلترهای Residual [[1]]\n",
        "    num_residuals=6     # کاهش تعداد Blockهای Residual [[2]]\n",
        ")\n",
        "\n",
        "generator_BtoA.load_state_dict(torch.load(res_mdl+\"generator_BtoA_epoch_\"+ str(mdl_ep)+\".pth\",map_location=device))\n",
        "generator_BtoA.to(device).eval()\n",
        "\n",
        "generator_AtoB = Generator(\n",
        "    init_filters=32,    # کاهش اولین لایه Downsampling [[1]]\n",
        "    mid_filters=64,     # کاهش لایه دوم Downsampling [[1]]\n",
        "    res_filters=128,    # کاهش تعداد فیلترهای Residual [[1]]\n",
        "    num_residuals=6     # کاهش تعداد Blockهای Residual [[2]]\n",
        ")\n",
        "generator_AtoB.load_state_dict(torch.load(res_mdl+\"generator_AtoB_epoch_\"+ str(mdl_ep)+\".pth\",map_location=device))\n",
        "generator_AtoB.to(device).eval()\n",
        "\n",
        "\n",
        "# random.shuffle(a_dt_imgs)\n",
        "# test_A_paths = a_dt_imgs[:cnt_g_img]\n",
        "test_A_paths = a_dt_imgs\n",
        "test_A = []\n",
        "for path in test_A_paths:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "    test_A.append(img)\n",
        "test_A = torch.cat(test_A, dim=0)  # [[9]]\n",
        "\n",
        "\n",
        "\n",
        "# During training, pass both generators and test images from domain A\n",
        "generate_show_save_images(\n",
        "    impths=test_A_paths,  # << Original paths of test images [[5]]\n",
        "    generator_a2b=generator_AtoB,\n",
        "    generator_b2a=generator_BtoA,\n",
        "    test_images=test_A,  # << Test images from domain A [[5]]\n",
        "    epoch=mdl_ep,\n",
        "    output_dir_a=a_ge_pth,\n",
        "    output_dir_b=b_ge_pth,\n",
        "    save=True,\n",
        "    filter_bw=False,\n",
        "    show=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruLbn9WmaAke"
      },
      "source": [
        "## bw images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiY5I1WmaLgO"
      },
      "outputs": [],
      "source": [
        "def generate_show_save_images(\n",
        "    impths,\n",
        "    generator_a2b,\n",
        "    generator_b2a,\n",
        "    test_images,\n",
        "    epoch,\n",
        "    output_dir_a='',\n",
        "    output_dir_b='',\n",
        "    save=False,\n",
        "    filter_bw=True,\n",
        "    show=False\n",
        "):\n",
        "    def gr(fake):\n",
        "        # Calculate layout: 2 columns (fake and recon), rows based on valid count\n",
        "\n",
        "        saturation_threshold = 127  # Adjust this to define \"gray\" (lower = more tolerance) [[1]]\n",
        "        min_value = 10  #50           # Mid-intensity range (50-200) [[2]]\n",
        "        max_value = 60 #200\n",
        "        pil_img = Image.fromarray(fake)\n",
        "        hsv_img = pil_img.convert(\"HSV\")\n",
        "        hsv_array = np.array(hsv_img)\n",
        "        # === Brighten Gray Pixels ===\n",
        "        gray_mask = hsv_array[..., 1] < saturation_threshold  # Low saturation (gray pixels)\n",
        "        mid_value_mask = (hsv_array[..., 2] > min_value) & (hsv_array[..., 2] < max_value)\n",
        "        combined_mask = gray_mask & mid_value_mask\n",
        "        # Increase Value (brightness) for gray pixels in midtones\n",
        "        hsv_array[..., 2][combined_mask] += 50  # << Adjust this value (e.g., 50 → 100 for stronger brightening) [[3]]\n",
        "        hsv_array[..., 2] = np.clip(hsv_array[..., 2], 0, 255)  # Clamp values to valid range\n",
        "        # Convert back to RGB and save\n",
        "        enhanced_hsv = Image.fromarray(hsv_array, \"HSV\")\n",
        "        enhanced_rgb = enhanced_hsv.convert(\"RGB\")\n",
        "        return enhanced_rgb\n",
        "\n",
        "\n",
        "\n",
        "    def re(recon): # با افزایش کانتراست و ...و چرخش\n",
        "        pil_recon = Image.fromarray(recon)\n",
        "        # === Random Rotation (Avoid Black Borders) ===\n",
        "        angle = random.choice([90, 180, 270])\n",
        "        rotated = pil_recon.rotate(angle, expand=True)  # << Use expand=True [[1]]\n",
        "        # === Boost Brightness (Random Factor 1.0–2.0) ===\n",
        "        brightness_enhancer = ImageEnhance.Brightness(rotated)\n",
        "        brightness_factor = random.uniform(1.0, 2.0)  # << Increase brightness [[2]]\n",
        "        brightened = brightness_enhancer.enhance(brightness_factor)\n",
        "        # === Enhance Contrast (Random Factor 1.0–2.0) ===\n",
        "        contrast_enhancer = ImageEnhance.Contrast(brightened)\n",
        "        contrast_factor = random.uniform(1.0, 2.0)  # << Sharpen contrast [[3]]\n",
        "        enhanced = contrast_enhancer.enhance(contrast_factor)\n",
        "        return enhanced\n",
        "\n",
        "    generator_a2b.eval()\n",
        "    generator_b2a.eval()\n",
        "    with torch.no_grad():\n",
        "        # Generate fake images\n",
        "        fake_images = generator_a2b(test_images.to(device))\n",
        "        # Generate reconstructed images (B→A)\n",
        "        recon_images = generator_b2a(fake_images)  # << Reconstruction added [[1]]\n",
        "\n",
        "    valid_images = []\n",
        "    for fake_tensor, recon_tensor, img_path in zip(fake_images, recon_images, impths):\n",
        "        # Process fake image\n",
        "        fake = ((fake_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n",
        "        # Process reconstructed image\n",
        "        recon = ((recon_tensor.cpu().numpy().transpose(1, 2, 0) + 1) * 127.5).astype(np.uint8)\n",
        "\n",
        "        # Filter fake images (reconstructed images are not filtered)\n",
        "        black_mask = np.all(fake < 20, axis=-1)\n",
        "        black_percent = (np.sum(black_mask) / fake.size) * 100\n",
        "        gray_mask = np.var(fake, axis=-1) < 30\n",
        "        gray_percent = (np.sum(gray_mask) / fake.size) * 100\n",
        "        if filter_bw:\n",
        "            if black_percent <= 10 and gray_percent <= 10:\n",
        "                valid_images.append((fake, recon, img_path))  # << Include recon [[2]]\n",
        "        else:\n",
        "            valid_images.append((fake, recon, img_path))\n",
        "\n",
        "    # Early exit if no valid images\n",
        "    if not valid_images:\n",
        "        print(\"No valid fake images to display.\")\n",
        "        return\n",
        "    num_pairs = len(valid_images)\n",
        "    rows = num_pairs\n",
        "    cols = 2\n",
        "    # Create figure\n",
        "\n",
        "    for i, (fake, recon, img_path) in enumerate(valid_images):\n",
        "        # === Fake Image ===\n",
        "        filename = os.path.basename(img_path)\n",
        "        if show:\n",
        "          fig = plt.figure(figsize=(cols * 4, rows * 4), dpi=72)  # << Adjusted size for 2 columns [[3]]\n",
        "          plt.subplot(rows, cols, 2*i + 1)  # << First column (fake)\n",
        "          plt.title(f\"Fake {i} - {filename}\", fontsize=8)\n",
        "          plt.axis('off')\n",
        "          plt.imshow(fake)\n",
        "          # plt.imshow(gr(fake))\n",
        "          plt.subplot(rows, cols, 2*i + 2)  # << Second column (reconstructed)\n",
        "          plt.title(f\"Recon {i} - {filename}\", fontsize=8)\n",
        "          plt.axis('off')\n",
        "          # plt.imshow(recon)\n",
        "          plt.imshow(re(recon))\n",
        "          plt.show()\n",
        "          plt.tight_layout()\n",
        "          plt.close()\n",
        "        if save:\n",
        "            fake_path = os.path.join(output_dir_a, f\"fk_{i}_e_{epoch}_{generate_timestamp_decimal()}.png\")\n",
        "            # Image.fromarray(fake).save(fake_path)\n",
        "            # gr(fake).save(fake_path)  # << Save the modified image [[4]]\n",
        "            re(fake).save(fake_path)\n",
        "            recon_path = os.path.join(output_dir_b, f\"rcn_{i}_e_{epoch}_{generate_timestamp_decimal()}.png\")\n",
        "            # Image.fromarray(recon).save(recon_path)\n",
        "            # Convert array to PIL Image\n",
        "            re(recon).save(recon_path)\n",
        "\n",
        "\n",
        "    # Final adjustments\n",
        "    # if save:\n",
        "    #   pass\n",
        "    #     # plt.savefig(os.path.join(output_dir, f\"epoch_{epoch}_comparison.png\"))  # << Save comparison figure [[4]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EXKF1u-bm_v",
        "outputId": "a7c14a60-d5cc-4b2a-d8d9-2ea57459bb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 16\n",
            "Neutrophil\n",
            "A data for Neutrophil: 300 ['/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_325_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_255_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_67_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-3_115_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-3_123_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_262_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_245_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_258_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_317_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_208_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-4_172_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-2_72_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_228_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-11-1_90_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_62_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_242_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_246_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_506_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_118_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_130_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_158_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_10_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_177_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_405_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_291_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_183_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_166_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_165_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_27_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-6_29_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_249_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-11-1_211_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_235_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_180_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_463_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-3_151_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-2_54_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-3_65_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_573_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-3_149_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_236_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_127_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_38_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-5_135_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_546_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_308_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-24-1_215_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-4_5_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_179_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-1_21_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_782_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-5_119_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-3_62_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-4_133_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_227_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_535_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-4_43_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_164_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-1_523_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-1_589_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_126_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_12_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_141_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-4_125_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-4_72_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-24-1_245_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_142_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_358_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-6_82_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_1054_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-3_76_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_256_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-3_30_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_225_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-3_180_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_83_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-1_159_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_588_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-4_166_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_198_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_127_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_81_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-1_220_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_634_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-1_152_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-3_122_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_373_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-3_18_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_696_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-2_102_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-3_114_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-5_128_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_256_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_120_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-4_36_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_49_5.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_1116_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-7-24-2_127_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_578_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-5_129_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-2_2_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_14_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_1089_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-6_73_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_221_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_155_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_177_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-6_139_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_257_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_538_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_130_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-6_7_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_337_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_137_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_984_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-2_8_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_128_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_127_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_161_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_367_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-4_48_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-1_164_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_165_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_874_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_558_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_53_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-2_269_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_696_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_172_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-3_93_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_407_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-3_2_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_284_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-11-1_205_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-4_73_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_245_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_851_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_186_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_21_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-6_31_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_289_5.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_865_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_263_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-24-2_7_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_201_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_232_5.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_44_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-4_38_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_445_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_223_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-4_230_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_289_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_172_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_329_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_591_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-1_53_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-4_36_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-11-1_80_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_1151_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-2_200_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_541_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_406_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_1123_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_192_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_431_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_42_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_162_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_857_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-1_206_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_53_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-6_21_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_144_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-3_151_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-4_65_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-4_92_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_469_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-2_174_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_518_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-3_120_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_434_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_378_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_55_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_711_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_376_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_133_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-3_108_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_17_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_320_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-3_15_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_285_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_83_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_317_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_20_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_10_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-4-1_365_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_868_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_938_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_922_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-3_71_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-2_74_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-5_240_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-3_23_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_127_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-2_4_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-24-1_2_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-6_29_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_458_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_644_5.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_301_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-3_284_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-1_261_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-3_48_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-1_109_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-1_80_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-1_23_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-4-1_407_12.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-4_12_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-5_27_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_10_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-6_103_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_426_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_265_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-5_41_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-7-24-2_444_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_203_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_608_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_484_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-2_9_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_399_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_285_7.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-4_132_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-4_44_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-22-3_83_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-24-2_136_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_189_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-1_61_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-2_172_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_326_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-4_134_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_276_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-1_389_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-4-1_176_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_694_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_207_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_285_6.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_208_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-2_158_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_141_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-3_73_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-5-1_99_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_369_6.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-3_24_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_134_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_473_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_438_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-3_26_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_519_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-6_41_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_985_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_297_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_498_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-7-24-2_320_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_246_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_234_3.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-7-24-2_223_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_136_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_22_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_454_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-6_32_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_465_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-5-10-1_864_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-2_453_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-3_40_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-7-24-2_397_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_94_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-27-1_403_7.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-22-1_77_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_118_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_600_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_203_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_336_4.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-1_11_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-6-1_742_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-20-2_25_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-2_83_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-8-1_408_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-7-24-2_356_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-4_126_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-13-4_128_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-5_42_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_578_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-10-1_917_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_603_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-12-4_113_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-1-2_325_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-3-1_592_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-9-4-6_153_2.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-9-3-4_190_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Test/Neutrophil/95-8-17-3_300_1.jpg', '/content/drive/.shortcut-targets-by-id/11uft3Rv8T4FYMqiUyk7cTxJ7DDDjnn79/Classification/Train/Neutrophil/95-8-1-1_378_1.jpg']\n"
          ]
        }
      ],
      "source": [
        "# cnt_g_img = 2 # 4 8 12 16\n",
        "mdl_ep = 16 # 4 8 12 16\n",
        "print(f'epoch: {mdl_ep}')\n",
        "print(pths[aim])\n",
        "generator_BtoA = Generator(\n",
        "    init_filters=32,    # کاهش اولین لایه Downsampling [[1]]\n",
        "    mid_filters=64,     # کاهش لایه دوم Downsampling [[1]]\n",
        "    res_filters=128,    # کاهش تعداد فیلترهای Residual [[1]]\n",
        "    num_residuals=6     # کاهش تعداد Blockهای Residual [[2]]\n",
        ")\n",
        "\n",
        "generator_BtoA.load_state_dict(torch.load(res_mdl_c+\"generator_BtoA_epoch_\"+ str(mdl_ep)+\".pth\",map_location=device))\n",
        "generator_BtoA.to(device).eval()\n",
        "\n",
        "generator_AtoB = Generator(\n",
        "    init_filters=32,    # کاهش اولین لایه Downsampling [[1]]\n",
        "    mid_filters=64,     # کاهش لایه دوم Downsampling [[1]]\n",
        "    res_filters=128,    # کاهش تعداد فیلترهای Residual [[1]]\n",
        "    num_residuals=6     # کاهش تعداد Blockهای Residual [[2]]\n",
        ")\n",
        "generator_AtoB.load_state_dict(torch.load(res_mdl_c+\"generator_AtoB_epoch_\"+ str(mdl_ep)+\".pth\",map_location=device))\n",
        "generator_AtoB.to(device).eval()\n",
        "\n",
        "\n",
        "# random.shuffle(a_dt_imgs)\n",
        "# test_A_paths = a_dt_imgs[:cnt_g_img]\n",
        "a_dt_imgs = []\n",
        "for path in a_dt_pth:\n",
        "  a_dt_imgs.extend([os.path.join(path, f) for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "random.shuffle(a_dt_imgs)\n",
        "a_dt_imgs = a_dt_imgs[:300]  # << Your random subset [[1]][[3]] 795  = len Monocyte\n",
        "print(f\"A data for {pths[aim]}:\",len(a_dt_imgs),a_dt_imgs)\n",
        "\n",
        "\n",
        "test_A_paths = a_dt_imgs\n",
        "test_A = []\n",
        "for path in test_A_paths:\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "    test_A.append(img)\n",
        "test_A = torch.cat(test_A, dim=0)  # [[9]]\n",
        "\n",
        "\n",
        "\n",
        "# During training, pass both generators and test images from domain A\n",
        "generate_show_save_images(\n",
        "    impths=test_A_paths,  # << Original paths of test images [[5]]\n",
        "    generator_a2b=generator_AtoB,\n",
        "    generator_b2a=generator_BtoA,\n",
        "    test_images=test_A,  # << Test images from domain A [[5]]\n",
        "    epoch=mdl_ep,\n",
        "    output_dir_a=a_ge_pth_c,\n",
        "    output_dir_b=b_ge_pth_c,\n",
        "    save=True,\n",
        "    filter_bw=False,\n",
        "    show=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#R3GAN implementation"
      ],
      "metadata": {
        "id": "_VCtnDrGBhZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# results_path = res_g\n",
        "\n",
        "\n",
        "# تنظیمات اولیه\n",
        "latent_dim = 4 #128\n",
        "image_size = 256  # اندازه تصویر 256x256 256\n",
        "batch_size = 1   # 8 # کاهش batch size برای تصاویر بزرگتر\n",
        "num_epochs = 5   # افزایش تعداد ایپوک برای آموزش بهتر\n",
        "\n",
        "intrvl = 2\n",
        "\n",
        "# Create dataset from paths\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(dt_imgs)\n",
        "\n",
        "# Define preprocessing function (ensure it returns a tensor with known shape)\n",
        "def load_and_preprocess_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_image(img, channels=3, dtype=tf.float32)  # << Read as RGB [[1]]\n",
        "    img.set_shape([image_size, image_size, 3])  # << Fixed shape (256x256x3) [[2]]\n",
        "    img = tf.image.resize(img, [image_size, image_size])  # << Resize ensures consistent dimensions [[2]]\n",
        "    img = (img / 127.5) - 1.0  # << Normalize to [-1, 1] [[5]]\n",
        "    return img\n",
        "\n",
        "train_dataset = train_dataset.map(\n",
        "    load_and_preprocess_image,\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ").batch(batch_size).shuffle(buffer_size=1000)  # << Final dataset setup [[1]][[2]]\n",
        "\n",
        "def build_generator(latent_dim, image_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    init_size = image_size // 32\n",
        "    model.add(layers.Dense(init_size * init_size * 512, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((init_size, init_size, 512)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(32, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    return model\n",
        "\n",
        "# تعریف تشخیص‌گر (Discriminator) برای تصاویر 256x256\n",
        "def build_discriminator(image_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=[image_size, image_size, 3]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(512, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# Define generator and discriminator\n",
        "generator = build_generator(latent_dim, image_size)\n",
        "discriminator = build_discriminator(image_size)\n",
        "\n",
        "# تابع از دست رساندن\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# تعریف تابع از دست رساندن برای مولد\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# تعریف تابع از دست رساندن برای تشخیص‌گر\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "# بهینه‌سازی\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "\n",
        "# Training loop (ensure shapes are correct before training)\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "# آموزش مدل\n",
        "def train(dataset, epochs):\n",
        "    # ایجاد فایل CSV اگر وجود ندارد\n",
        "    csv_file = lss_g + pths[-1] + '_cygan_loss.csv'\n",
        "    if not os.path.exists(csv_file):\n",
        "        with open(csv_file, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow([\"Epoch\", \"Generator Loss\", \"Discriminator Loss\"])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for image_batch in dataset:\n",
        "          gen_loss, disc_loss = train_step(image_batch)\n",
        "\n",
        "      with open(csv_file, mode='a', newline='') as file:\n",
        "          writer = csv.writer(file)\n",
        "          writer.writerow([epoch + 1, gen_loss.numpy(), disc_loss.numpy()])\n",
        "      print(f\"Epoch {epoch}/{epochs}, Generator Loss: {gen_loss.numpy():.4f}, Discriminator Loss: {disc_loss.numpy():.4f}\")\n",
        "      generate_and_save_images(generator, epoch + 1, seed,sv=False)\n",
        "      # هر 20 تا در پنجره پایین نمایش میده\n",
        "      # if epoch % intrvl == 0:\n",
        "      #       # نمایش و ذخیره تصاویر تولید شده\n",
        "      #       generate_and_save_images(generator, epoch + 1, seed,sv=True)\n",
        "\n",
        "# تابع نمایش و ذخیره تصاویر رنگی\n",
        "def generate_and_save_images(model, epoch, test_input,sv=False):\n",
        "    predictions = model(test_input, training=False)\n",
        "    fig = plt.figure(figsize=(8, 8), dpi = 72)\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        img = (predictions[i] * 127.5 + 127.5).numpy().astype(np.uint8)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    if sv:\n",
        "      save_path = os.path.join(res_g, f'epc_{epoch:04d}.png')\n",
        "      plt.savefig(save_path)\n",
        "    plt.close(fig)  # بستن شکل برای جلوگیری از مصرف حافظه زیاد\n",
        "\n",
        "# تعریف ورودی ثابت برای نمایش تصاویر\n",
        "seed = tf.random.normal([16, latent_dim])\n",
        "\n",
        "# شروع آموزش\n",
        "# train(train_dataset, num_epochs)\n",
        "train(train_dataset, num_epochs)"
      ],
      "metadata": {
        "id": "Hkwn49gZCYuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# === Initial Setup ===\n",
        "image_size = 256\n",
        "latent_dim = 100  # Fixed latent dimension [[1]]\n",
        "batch_size = 2\n",
        "num_epochs = 40\n",
        "intrvl = 5\n",
        "lr = 0.00005 #0.0001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "csv_file = Path(lss_g + pths[aim] + '_g_lss.csv')\n",
        "csv_file.touch(exist_ok=True)\n",
        "\n",
        "# === Dataset Creation ===\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths):\n",
        "        self.image_paths = image_paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1,1] [[5]]\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        return self.transform(img)\n",
        "\n",
        "train_dataset = ImageDataset(dt_imgs)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Verify dataset shape\n",
        "for batch in train_loader:\n",
        "    assert batch.shape == (batch_size, 3, image_size, image_size), f\"Batch shape mismatch: {batch.shape}\"\n",
        "    break\n",
        "\n",
        "# === Generator Architecture ===\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, image_size):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.image_size = image_size\n",
        "\n",
        "        # Initial linear projection\n",
        "        self.initial_linear = nn.Linear(latent_dim, 512 * 8 * 8)  # (batch, 512*8*8)\n",
        "\n",
        "        # Reshape to (batch, 512, 8, 8)\n",
        "        self.up1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 16x16\n",
        "\n",
        "        self.up2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 32x32\n",
        "\n",
        "        self.up3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 64x64\n",
        "\n",
        "        self.up4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )  # → 128x128\n",
        "\n",
        "        self.final = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )  # → 256x256\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Map noise to linear space\n",
        "        x = self.initial_linear(x)\n",
        "        # Reshape to 512x8x8 [[1]]\n",
        "        x = x.view(-1, 512, 8, 8)  # << Critical reshape [[1]]\n",
        "\n",
        "        x = self.up1(x)\n",
        "        x = self.up2(x)\n",
        "        x = self.up3(x)\n",
        "        x = self.up4(x)\n",
        "        return self.final(x)\n",
        "\n",
        "# === Discriminator Architecture ===\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_size):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),  # Global pooling [[5]]\n",
        "            nn.Flatten(),  # (batch, 512)\n",
        "            nn.Linear(512, 1)  # Scalar output [[5]]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator(latent_dim, image_size).to(device)\n",
        "discriminator = Discriminator(image_size).to(device)\n",
        "\n",
        "# Define loss and optimizers\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)  # Binary cross entropy [[5]]\n",
        "\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Custom weight initialization\n",
        "def weights_init(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.Linear)):\n",
        "        torch.nn.init.normal_(m.weight, mean=0.0, std=0.02)  # << Replicating TF initialization [[3]]\n",
        "\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# === Loss Functions ===\n",
        "def generator_loss(fake_output):\n",
        "    return criterion(fake_output, torch.ones_like(fake_output).to(device))\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = criterion(real_output, torch.ones_like(real_output).to(device))\n",
        "    fake_loss = criterion(fake_output, torch.zeros_like(fake_output).to(device))\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "# === Training Loop ===\n",
        "def train_step(images):\n",
        "    valid = torch.ones(images.size(0), 1, device=device)\n",
        "    fake = torch.zeros(images.size(0), 1, device=device)\n",
        "\n",
        "    # Train Generator\n",
        "    generator_optimizer.zero_grad()\n",
        "    z = torch.randn(images.size(0), latent_dim, device=device)\n",
        "    generated_images = generator(z)\n",
        "    g_loss = generator_loss(discriminator(generated_images))\n",
        "    g_loss.backward()\n",
        "    generator_optimizer.step()\n",
        "\n",
        "    # Train Discriminator\n",
        "    discriminator_optimizer.zero_grad()\n",
        "    real_pred = discriminator(images)\n",
        "    fake_pred = discriminator(generated_images.detach())\n",
        "    d_loss_real = criterion(real_pred, valid)\n",
        "    d_loss_fake = criterion(fake_pred, fake)\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    d_loss.backward()\n",
        "    discriminator_optimizer.step()\n",
        "\n",
        "    return g_loss.item(), d_loss.item()\n",
        "\n",
        "# === Image Generation Function ===\n",
        "# def generate_and_save_images(model, epoch, test_input, sv=False):\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         predictions = model(test_input).cpu()\n",
        "#     if sv:\n",
        "#       d=300\n",
        "#     else:\n",
        "#       d=36\n",
        "#     fig = plt.figure(figsize=(8, 8), dpi=d)\n",
        "#     for i in range(predictions.shape[0]):\n",
        "#         plt.subplot(4, 4, i+1)\n",
        "#         img = ((predictions[i].numpy().transpose(1, 2, 0) + 1) / 2 * 255).astype(np.uint8)\n",
        "#         plt.imshow(img)\n",
        "#         plt.axis('off')\n",
        "\n",
        "#     if sv:\n",
        "#         plt.savefig(os.path.join(res_g, f'epc_{epoch:04d}.png'))\n",
        "#     plt.show()\n",
        "#     plt.close(fig)\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, sv=False):\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    num_samples=16\n",
        "    # Generate new random noise each time\n",
        "    noise = torch.randn(num_samples, latent_dim, device=device)  # << Random seed every call [[1]]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_images = model(noise).cpu()  # Generate and move to CPU [[2]]\n",
        "\n",
        "    d = 36\n",
        "    if sv:\n",
        "      d = 300\n",
        "    # Prepare to show images\n",
        "    fig = plt.figure(figsize=(8, 8), dpi=d)\n",
        "    rows = cols = int(np.ceil(np.sqrt(num_samples)))  # Dynamic layout\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.axis('off')\n",
        "        img = ((generated_images[i] * 0.5 + 0.5) * 255).clamp(0, 255).permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "        plt.imshow(img)\n",
        "        if sv:\n",
        "          plt.savefig(os.path.join(res_g, f'epc_{epoch:04d}.png'),bbox_inches='tight')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "# === Start Training ===\n",
        "def train(dataset, epochs):\n",
        "    flg = True\n",
        "    with open(csv_file, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Epoch\", \"Generator Loss\", \"Discriminator Loss\"])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_images in dataset:\n",
        "            real_images = real_images.to(device)\n",
        "            gen_loss, disc_loss = train_step(real_images)\n",
        "        with open(csv_file, 'a', newline='') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([epoch+1, gen_loss, disc_loss])\n",
        "\n",
        "        if (epoch + 1) % intrvl == 0:\n",
        "            flg = False\n",
        "            generate_and_save_images(generator, epoch+1, sv=True)\n",
        "            torch.save(generator.state_dict(), f\"{res_mdl_g}e_{epoch+1}.pth\")\n",
        "\n",
        "        else:\n",
        "            flg = True\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"  Generator Loss: {gen_loss:.4f}\")\n",
        "        print(f\"  Discriminator Loss: {disc_loss:.4f}\")\n",
        "        if flg:\n",
        "          generate_and_save_images(generator, epoch+1, sv=False)\n",
        "\n",
        "# Initialize seed\n",
        "# seed = torch.randn(16, latent_dim, device=device)\n",
        "# Start training\n",
        "print(f\"Using {'GPU' if device.type == 'cuda' else 'CPU'} acceleration\")\n",
        "print(pths[aim])\n",
        "print('batch_size: ', batch_size)\n",
        "print('num_epochs: ', num_epochs)\n",
        "print('lr: ', lr)\n",
        "print('image_size: ', image_size)\n",
        "print('intrvl: ', intrvl)\n",
        "train(train_loader, num_epochs)"
      ],
      "metadata": {
        "id": "x92gzdRSCcyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load model to generate new images"
      ],
      "metadata": {
        "id": "ITy-8gzDClnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_timestamp_decimal():\n",
        "    current_time = datetime.datetime.now()  # [[2]]\n",
        "    date_part = current_time.strftime(\"%d-%m-%y\")  # Day-Month-Last two digits of year [[3]]\n",
        "    time_part = current_time.strftime(\"%H-%M-%S\")  # Hour:Minute:Second [[2]]\n",
        "    decimal_num = int(round(random.uniform(0, 1) * 1000))  # << Key adjustment [[5]][[9]]\n",
        "    return f\"{date_part}-{time_part}-{decimal_num}\"\n",
        "\n",
        "result = generate_timestamp_decimal()\n",
        "print(result)  # Output: \"15-04-25 14:30:45 0.123\" [[1]][[2]][[3]]\n",
        "# New method for generating random images from saved model\n",
        "def generate_random_images(model_path, num_images=16, sv=False,sh=False,o_d=None,ep=0):\n",
        "\n",
        "    # Load model architecture\n",
        "    gen = Generator(latent_dim,image_size).to(device)\n",
        "\n",
        "    # Load weights\n",
        "    try:\n",
        "        gen.load_state_dict(torch.load(model_path, map_location=device))\n",
        "        print(f\"Model loaded from {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    gen.eval()\n",
        "\n",
        "    # Generate random noise\n",
        "    noise = torch.randn(num_images, latent_dim, device=device)\n",
        "\n",
        "    # Generate images\n",
        "    with torch.no_grad():\n",
        "        fake_images = gen(noise)\n",
        "\n",
        "    # Create figure for visualization\n",
        "    if sh:\n",
        "      fig = plt.figure(figsize=(8, 8))\n",
        "      columns = min(4, num_images)\n",
        "      rows = (num_images + columns - 1) // columns\n",
        "\n",
        "      for i in range(num_images):\n",
        "          plt.subplot(rows, columns, i+1)\n",
        "          img = ((fake_images[i].cpu() * 0.5 + 0.5) * 255).clamp(0, 255).permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "          plt.imshow(img)\n",
        "          plt.axis('off')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      plt.close(fig)\n",
        "\n",
        "\n",
        "    # Save individual images if output_dir specified\n",
        "    if sv:\n",
        "      for i in range(num_images):\n",
        "          img = ((fake_images[i].cpu() * 0.5 + 0.5) * 255).clamp(0, 255).permute(1, 2, 0).numpy().astype(np.uint8)\n",
        "          Image.fromarray(img).save(f\"{o_d}/geg_epc_{str(ep)}_{i:03d}_{generate_timestamp_decimal()}.png\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LKOXvdoPCq45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBh6JykiyYYR"
      },
      "source": [
        "# GAN Mertics: Fréchet Inception Distance (FID) Inception Score (IS) Structural Similarity Index (SSIM) Perceptual Path Length (PPL) LPIPS (Learned Perceptual Image Patch Similarity) Mode Score Precision & Recall   Kernel Inception Distance (KID) PSNR (Peak Signal-to-Noise Ratio)  (Distribution Approximation (Probability Calibration (Distribution Matching  \n",
        "'''\n",
        "1- Fréchet Inception Distance (FID) #Ok\n",
        "2- Inception Score (IS) #Ok\n",
        "3- Kernel Inception Distance (KID) #Ok\n",
        "4- LPIPS (Learned Perceptual Image Patch Similarity) #Ok\n",
        "5- Structural Similarity Index (SSIM) # ok\n",
        "6- PSNR (Peak Signal-to-Noise Ratio) # ok\n",
        "7- Perceptual Path Length (PPL)\n",
        "8- Mode Score Precision & Recall\n",
        "9- (Distribution Approximation)\n",
        "10- (Probability Calibration)\n",
        "11- (Distribution Matching)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqZ8zUI-yZvg"
      },
      "outputs": [],
      "source": [
        "def evaluate_gan_metrics_1_4(original_dir, generated_dir):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Calculate FID, Inception Score, KID using torch_fidelity\n",
        "    metrics = torch_fidelity.calculate_metrics(\n",
        "        input1=original_dir,  # Original images directory [[1]]\n",
        "        input2=generated_dir,  # Generated images directory [[1]]\n",
        "        cuda=torch.cuda.is_available(),\n",
        "        isc=True,  # Inception Score\n",
        "        fid=True,  # Fréchet Inception Distance\n",
        "        kid=True,  # Kernel Inception Distance\n",
        "        kid_subset_size=10  # Adjust based on dataset size [[6]]\n",
        "    )\n",
        "\n",
        "    # Extract metrics\n",
        "    fid_score = metrics['frechet_inception_distance']\n",
        "    is_mean = metrics['inception_score_mean']\n",
        "    kid_mean = metrics['kernel_inception_distance_mean']\n",
        "\n",
        "    # SSIM and PSNR with proper resizing and win_size\n",
        "    original_images = [\n",
        "        os.path.join(original_dir, f)\n",
        "        for f in os.listdir(original_dir)\n",
        "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "    ]\n",
        "    generated_images = [\n",
        "        os.path.join(generated_dir, f)\n",
        "        for f in os.listdir(generated_dir)\n",
        "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "    ]\n",
        "\n",
        "    min_len = min(len(original_images), len(generated_images))\n",
        "\n",
        "\n",
        "    # # Calculate LPIPS\n",
        "    transform_fid = transforms.Compose([\n",
        "        transforms.Resize(image_size),  # Use training image_size [[5]]\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Match training normalization [[5]]\n",
        "    ])\n",
        "\n",
        "    tensors_A = []\n",
        "    tensors_B = []\n",
        "    for i in range(min_len):\n",
        "        try:\n",
        "            img_A = Image.open(original_images[i]).convert(\"RGB\")\n",
        "            img_B = Image.open(generated_images[i]).convert(\"RGB\")\n",
        "\n",
        "            tensors_A.append(transform_fid(img_A).to(device))\n",
        "            tensors_B.append(transform_fid(img_B).to(device))\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading LPIPS tensors: {e}\")\n",
        "            continue\n",
        "\n",
        "    if tensors_A and tensors_B:\n",
        "        tensors_A = torch.stack(tensors_A)\n",
        "        tensors_B = torch.stack(tensors_B)\n",
        "        loss_fn = lpips.LPIPS(net='alex').to(device)\n",
        "        avg_lpips = loss_fn(tensors_A, tensors_B).mean().item()\n",
        "    else:\n",
        "        avg_lpips = np.nan\n",
        "\n",
        "    # Print results\n",
        "    print(f\"FID: {fid_score:.2f}\")\n",
        "    print(f\"Inception Score (Mean ± Std): {is_mean:.2f} ± {metrics['inception_score_std']:.2f}\")\n",
        "    print(f\"Kernel Inception Distance (Mean ± Std): {kid_mean:.4f} ± {metrics['kernel_inception_distance_std']:.4f}\")\n",
        "    print(f\"LPIPS: {avg_lpips:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNhkPs19ypxI"
      },
      "outputs": [],
      "source": [
        "# a_dt_pth\n",
        "# b_dt_pth\n",
        "# a_ge_pth\n",
        "# b_ge_pth\n",
        "# a_dt_imgs\n",
        "# b_dt_imgs\n",
        "# a_ge_imgs\n",
        "# b_ge_imgs\n",
        "# ge_imgs\n",
        "# path\n",
        "evaluate_gan_metrics_1_4(\n",
        "    a_dt_pth,\n",
        "    ge_pth_g\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SntgBamIRha2"
      },
      "source": [
        "# ConvNext V2+Swin Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install libs and import"
      ],
      "metadata": {
        "id": "JW6e_86IDGgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchinfo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
        "import time\n",
        "import timm\n",
        "import csv\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "nLlA84IlC9Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initial variables"
      ],
      "metadata": {
        "id": "YhcxF2yiDSd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# افزودن تمام تصاوير گلبولهاي سفيد براي آموزش يا حتي تست\n",
        "root = '/content/drive/MyDrive/Colab Notebooks/Projects_Files/'\n",
        "root_db = root + 'Blood_Cell/Rabin_White_Blood_Cell/'\n",
        "cls = root_db + 'Classification/'\n",
        "c_tr = cls + 'Train/'\n",
        "c_ts = cls + 'Test/'\n",
        "seg = root_db  + 'Segmentation/Original/'\n",
        "pr_mdl = root + 'timm/conv_next_v2/pre_train_models/convnextv2_tiny_1k_224_fcmae.pt'\n",
        "# sv_mdl = root + 'timm/conv_next_v2/models/convnextv2.pt'\n",
        "# csv_ls = root + 'timm/conv_next_v2/loss_res/training_log.csv'\n",
        "# '/content/drive/MyDrive/Colab Notebooks/Projects_Files/Blood_Cell/Rabin_White_Blood_Cell/Segmentation/Original/Basophil/xxx.jpg']\n",
        "\n",
        "# paths = [cls+'Train/', cls+'Test/', seg] # کل 15657\n",
        "# paths = [dvrs] # دایورس متنوع 362\n",
        "or_pths = [c_tr, c_ts] #seg تکراریه\n",
        "or_imgs = []\n",
        "sl = '/'\n",
        "fltrs=['Basophil'+sl,'Eosinophil'+sl,'Lymphocyte'+sl,'Monocyte'+sl,'Neutrophil'+sl]\n",
        "# fltrs=['Eosinophil'+sl]\n",
        "for path in or_pths:\n",
        "  i=0\n",
        "  # fldrs = [f for f in os.listdir(path)]\n",
        "  fldrs = fltrs\n",
        "  for fldr in fldrs:\n",
        "      # print(fldr)\n",
        "      len_fldr = [f for f in os.listdir(path+fldr) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "      for _file in len_fldr:\n",
        "        or_imgs.append(path + fldrs[i] + _file)\n",
        "      i = i+1\n",
        "    # print(len(len_fldr))\n",
        "or_imgs.sort()\n",
        "print('original paths: ',len(or_imgs),or_imgs[-10:-1])\n",
        "\n",
        "\n",
        "\n",
        "# Original images\n",
        "ln_mn = 795\n",
        "basophil_paths = [path for path in or_imgs if 'Basophil' in path]\n",
        "print('basophil: ',len(basophil_paths),basophil_paths[-10:-1])\n",
        "random.shuffle(basophil_paths)\n",
        "basophil_paths = basophil_paths[:ln_mn]\n",
        "print('basophil after: ',len(basophil_paths),basophil_paths)\n",
        "\n",
        "eosinophil_paths = [path for path in or_imgs if 'Eosinophil' in path]\n",
        "print('eosinophil: ',len(eosinophil_paths),eosinophil_paths[-10:-1])\n",
        "random.shuffle(eosinophil_paths)\n",
        "eosinophil_paths = eosinophil_paths[:ln_mn]\n",
        "print('eosinophil after: ',len(eosinophil_paths),eosinophil_paths)\n",
        "\n",
        "lymphocyte_paths = [path for path in or_imgs if 'Lymphocyte' in path]\n",
        "print('lymphocyte: ',len(lymphocyte_paths),lymphocyte_paths[-10:-1])\n",
        "random.shuffle(lymphocyte_paths)\n",
        "lymphocyte_paths = lymphocyte_paths[:ln_mn]\n",
        "print('lymphocyte after: ',len(lymphocyte_paths),lymphocyte_paths)\n",
        "\n",
        "monocyte_paths = [path for path in or_imgs if 'Monocyte' in path]\n",
        "print('monocyte: ',len(monocyte_paths),monocyte_paths[-10:-1])\n",
        "random.shuffle(monocyte_paths)\n",
        "monocyte_paths = monocyte_paths[:ln_mn]\n",
        "print('monocyte after: ',len(monocyte_paths),monocyte_paths)\n",
        "\n",
        "neutrophil_paths = [path for path in or_imgs if 'Neutrophil' in path]\n",
        "print('neutrophil: ',len(neutrophil_paths),neutrophil_paths[-10:-1])\n",
        "random.shuffle(neutrophil_paths)\n",
        "neutrophil_paths = neutrophil_paths[:ln_mn]\n",
        "print('neutrophil after: ',len(neutrophil_paths),neutrophil_paths)\n",
        "\n",
        "or_imgs_tr = basophil_paths + eosinophil_paths + lymphocyte_paths + monocyte_paths +  neutrophil_paths\n",
        "print('or_imgs_tr: ',len(or_imgs_tr),or_imgs_tr)\n",
        "\n",
        "# Generated GAN\n",
        "g_rt = '/content/drive/.shortcut-targets-by-id/1-3MblmfPfguMrEIIxIDUE4L0RaHDqFpt/GeG/'\n",
        "g_imgs = []\n",
        "g_pths = [g_rt] #seg تکراریه\n",
        "for path in g_pths:\n",
        "  i=0\n",
        "  # fldrs = [f for f in os.listdir(path)]\n",
        "  fldrs = fltrs\n",
        "  for fldr in fldrs:\n",
        "      len_fldr = [f for f in os.listdir(path+fldr) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
        "      for _file in len_fldr:\n",
        "        g_imgs.append(path + fldrs[i] + _file)\n",
        "      i = i+1\n",
        "    # print(len(len_fldr))\n",
        "g_imgs.sort()\n",
        "print('g_imgs: ',len(g_imgs),g_imgs)\n",
        "\n",
        "\n",
        "# GAN images\n",
        "basophil_paths = [path for path in g_imgs if 'Basophil' in path]\n",
        "print('basophil gan: ',len(basophil_paths),basophil_paths[-10:-1])\n",
        "random.shuffle(basophil_paths)\n",
        "# basophil_paths = basophil_paths[:ln_mn]\n",
        "print('basophil gan after: ',len(basophil_paths),basophil_paths)\n",
        "\n",
        "eosinophil_paths = [path for path in g_imgs if 'Eosinophil' in path]\n",
        "print('eosinophil gan: ',len(eosinophil_paths),eosinophil_paths[-10:-1])\n",
        "random.shuffle(eosinophil_paths)\n",
        "eosinophil_paths = eosinophil_paths[:ln_mn]\n",
        "print('eosinophil gan after: ',len(eosinophil_paths),eosinophil_paths)\n",
        "\n",
        "lymphocyte_paths = [path for path in g_imgs if 'Lymphocyte' in path]\n",
        "print('lymphocyte gan: ',len(lymphocyte_paths),lymphocyte_paths[-10:-1])\n",
        "random.shuffle(lymphocyte_paths)\n",
        "lymphocyte_paths = lymphocyte_paths[:600]\n",
        "print('lymphocyte gan after: ',len(lymphocyte_paths),lymphocyte_paths)\n",
        "\n",
        "monocyte_paths = [path for path in g_imgs if 'Monocyte' in path]\n",
        "print('monocyte gan: ',len(monocyte_paths),monocyte_paths[-10:-1])\n",
        "random.shuffle(monocyte_paths)\n",
        "# monocyte_paths = monocyte_paths[:ln_mn]\n",
        "print('monocyte gan after: ',len(monocyte_paths),monocyte_paths)\n",
        "\n",
        "neutrophil_paths = [path for path in g_imgs if 'Neutrophil' in path]\n",
        "print('neutrophil gan: ',len(neutrophil_paths),neutrophil_paths[-10:-1])\n",
        "random.shuffle(neutrophil_paths)\n",
        "neutrophil_paths = neutrophil_paths[:600]\n",
        "print('neutrophil gan after: ',len(neutrophil_paths),neutrophil_paths)\n",
        "\n",
        "g_imgs_tr = basophil_paths + eosinophil_paths + lymphocyte_paths + monocyte_paths +  neutrophil_paths\n",
        "print('g_imgs_tr: ',len(g_imgs_tr),g_imgs_tr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sv_mdl = root + 'timm/conv_next_v2/models/c_15g.pt'  # c_g2 c_g c c_3g\n",
        "csv_ls = root + 'timm/conv_next_v2/loss_res/c_15g.csv'\n",
        "print(sv_mdl)\n",
        "print(csv_ls)\n",
        "\n",
        "gln = len(g_imgs_tr)\n",
        "print('gln: ',gln)\n",
        "random.shuffle(g_imgs_tr)\n",
        "g_imgs_tr = g_imgs_tr[:gln//15]\n",
        "print('gln: ',gln)\n",
        "image_paths = or_imgs_tr + g_imgs_tr\n",
        "#or_imgs_tr + g_imgs_tr: 7046, or_imgs_tr(3565) + g_imgs_tr//2 : 5263, or_imgs_tr + g_imgs_tr//3: 4669   or_imgs_tr + g_imgs_tr//15 : 3718   or_imgs_tr (3565)\n",
        "\n",
        "\n",
        "\n",
        "print('image_paths: ',len(image_paths),image_paths)"
      ],
      "metadata": {
        "id": "MePxwrmdDVYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## extract labels from paths"
      ],
      "metadata": {
        "id": "-1ikpCQ2Dfb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استخراج برچسب از مسیر تصاویر\n",
        "def get_label_from_path(path):\n",
        "    return os.path.basename(os.path.dirname(path))  # مثال: 'x' یا 'y' [[1]]\n",
        "\n",
        "labels = [get_label_from_path(p) for p in image_paths]\n",
        "print(len(labels))\n",
        "class_names = list(sorted(set(labels)))  # لیست کلاس ها\n",
        "print(class_names)\n",
        "num_classes = len(class_names)\n",
        "print(num_classes)\n",
        "# تبدیل برچسب به عدد\n",
        "label_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "print(len(label_to_idx))\n",
        "print(label_to_idx)\n",
        "targets = [label_to_idx[label] for label in labels]\n",
        "print(targets)\n",
        "print(len(targets))"
      ],
      "metadata": {
        "id": "Pedewk6tDayD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split data to train test validation"
      ],
      "metadata": {
        "id": "N0YLjA-YDsTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# تقسیم داده به ترین، ولیدیشن، تست\n",
        "current_seed = int(time.time())  # استفاده از زمان فعلی [[1]][[2]]\n",
        "\n",
        "train_paths, temp_paths, train_targets, temp_targets = train_test_split(\n",
        "    image_paths, targets, test_size=0.1, random_state=current_seed, shuffle=True\n",
        ")\n",
        "print(len(train_paths))\n",
        "print(train_paths[0:5])\n",
        "print(len(train_targets))\n",
        "print(train_targets[0:5])\n",
        "val_paths, test_paths, val_targets, test_targets = train_test_split(\n",
        "    temp_paths, temp_targets, test_size=0.5, random_state=current_seed, shuffle=True\n",
        ")\n",
        "\n",
        "print(len(val_paths))\n",
        "print(val_targets[0:5])\n",
        "print(len(test_paths))\n",
        "print(test_targets[0:5])"
      ],
      "metadata": {
        "id": "CEJwVL6UDw-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate dataset"
      ],
      "metadata": {
        "id": "M9o9eVGzD11Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# کلاس دیتاست سفارشی\n",
        "class CustomImageDataset(data.Dataset):\n",
        "    def __init__(self, paths, targets, transform=None):\n",
        "        self.paths = paths\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.paths[idx]\n",
        "        label = self.targets[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "mTyGMwPLDyxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transformer and traing varibles"
      ],
      "metadata": {
        "id": "mkWZS-L0D9tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epchs = 30\n",
        "lr = 0.0002\n",
        "best_val_loss = float('inf')\n",
        "save_path = sv_mdl\n",
        "im_sz = 256\n",
        "t_im_sz = 224\n",
        "rotate = 10\n",
        "bch = 4\n",
        "# تبدیل کننده تصاویر\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(im_sz),  # تنظیم ابعاد [[5]][[7]]\n",
        "    transforms.RandomHorizontalFlip(),  # افزونی داده [[5]]\n",
        "    transforms.RandomRotation(rotate),      # دوران تصادفی [[5]]\n",
        "    transforms.CenterCrop(t_im_sz),         # قطعه گیری مرکزی [[2]]\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize(im_sz),\n",
        "    transforms.CenterCrop(t_im_sz),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# ساخت دیتاستها و لودرها\n",
        "train_dataset = CustomImageDataset(train_paths, train_targets, transform=train_transform)\n",
        "val_dataset = CustomImageDataset(val_paths, val_targets, transform=val_test_transform)\n",
        "test_dataset = CustomImageDataset(test_paths, test_targets, transform=val_test_transform)\n",
        "\n",
        "# train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# val_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "# test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bch, shuffle=True, pin_memory=True, num_workers=4)  # [[2]][[4]]\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=bch, shuffle=False, pin_memory=True, num_workers=4)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=bch, shuffle=False, pin_memory=True, num_workers=4)"
      ],
      "metadata": {
        "id": "OPhb05xZD7yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load ConvNext V2 model"
      ],
      "metadata": {
        "id": "RW8e3zWREFjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "۱. convnext_v2_tiny\n",
        "\n",
        "    پارامترها : ~۵.۲ میلیون\n",
        "    سرعت : بالا\n",
        "    دقت : پایین تر از وariantهای بزرگتر\n",
        "    استفاده : داده های کوچک و سیستم های کم منابع\n",
        "\n",
        "    .\n",
        "\n",
        "\n",
        "۲. convnext_v2_small\n",
        "\n",
        "    پارامترها : ~۲۲ میلیون\n",
        "    سرعت : متوسط\n",
        "    دقت : مناسب برای کاربردهای عمومی\n",
        "    استفاده : کلاسیفیکیشن تصاویر ساده\n",
        "\n",
        "    .\n",
        "\n",
        "\n",
        "۳. convnext_v2_base\n",
        "\n",
        "    پارامترها : ~50 میلیون\n",
        "    سرعت : مناسب\n",
        "    دقت : بالا برای داده های متوسط\n",
        "\n",
        "    .\n",
        "\n",
        "\n",
        "۴. convnext_v2_large\n",
        "\n",
        "    پارامترها : ~۱۳۴ میلیون\n",
        "    سرعت : کندتر از variantهای کوچکتر\n",
        "    دقت : بالاترین عملکرد\n",
        "\n",
        "    .\n",
        "\n",
        "\n",
        "۵. convnext_v2_huge\n",
        "\n",
        "    پارامترها : ~۲۰۰ میلیون\n",
        "    سرعت : بسیار کند\n",
        "    دقت : بهینه برای داده های پیچیده\n",
        "\n",
        "    .\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "# ساخت مدل\n",
        "# model = timm.create_model('hf_hub:timm/convnextv2_tiny.fcmae_ft_in22k_in1k', pretrained=True)  # [[1]][[2]]\n",
        "\n",
        "\n",
        "\n",
        "# لود فایل وزن ها\n",
        "checkpoint = torch.load(pr_mdl)\n",
        "state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint  # حذف کلید 'model' [[2]]\n",
        "\n",
        "# ایجاد مدل با timm\n",
        "model = timm.create_model('convnextv2_tiny.fcmae', pretrained=False, num_classes=num_classes)  # [[1]]\n",
        "\n",
        "# تنظیم state_dict با strict=False\n",
        "model.load_state_dict(state_dict, strict=False)  # [[3]]\n",
        "\n",
        "\n",
        "\n",
        "# حتما ایبجا رو ویژوال کن\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=(1, 3, 224, 224),  # (batch, channels, height, width)\n",
        "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\"],\n",
        "    depth=1  # Increase to see more details\n",
        ")"
      ],
      "metadata": {
        "id": "Efk0vSWlELyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## implemant training"
      ],
      "metadata": {
        "id": "0aJx1TyKEOBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# تنظیمات آموزش\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # تابع هزینه [[1]]\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ایجاد فایل CSV قبل از آموزش\n",
        "csv_file = csv_ls\n",
        "if not os.path.exists(csv_file):\n",
        "    with open(csv_file, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['Epoch', 'Train Loss (%)', 'Val Loss (%)'])\n",
        "\n",
        "# حلقه آموزش\n",
        "for epoch in range(epchs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        # images, labels = images.to(device), labels.to(device)\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)  # [[1]][[5]]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_train_loss = (train_loss / len(train_dataset)) * 100  # به درصد تبدیل [[1]]\n",
        "    avg_val_loss = (val_loss / len(val_dataset)) * 100\n",
        "    print(f'Epoch {epoch+1}/{epchs}, Train Loss: {avg_train_loss:.2f}%, Val Loss: {avg_val_loss:.2f}%')\n",
        "\n",
        "    # ذخیره در فایل CSV\n",
        "    with open(csv_file, 'a', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([epoch+1, avg_train_loss, avg_val_loss])\n",
        "\n",
        "    # ذخیره مدل بهترین\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f'Best model saved at {save_path}')"
      ],
      "metadata": {
        "id": "CNaz49-iEY6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading model for showing results as confusion matrix"
      ],
      "metadata": {
        "id": "NV6xT70jEjmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sv_mdl = root + 'timm/conv_next_v2/models/c_g.pt'  # c_g2 c_g c c_3g c_15g\n",
        "\n",
        "save_path = sv_mdl\n",
        "\n",
        "# {'Basophil': 0, 'Eosinophil': 1, 'Lymphocyte': 2, 'Monocyte': 3, 'Neutrophil': 4}\n",
        "# Example class names (replace with your actual class names)\n",
        "class_names = ['B', 'E', 'L', 'M', 'N']  # << Replace with your actual class names\n",
        "themes = {\n",
        "    'Blues': 'Blues',\n",
        "    'Greens': 'Greens',\n",
        "    'Reds': 'Reds',\n",
        "    'Purples': 'Purples',\n",
        "    'YlGnBu': 'YlGnBu',\n",
        "    'YlOrRd': 'YlOrRd',\n",
        "    'GnBu': 'GnBu',\n",
        "    'BuPu': 'BuPu',\n",
        "    'YlGn': 'YlGn',\n",
        "    'PuBu': 'PuBu',\n",
        "    'RdPu': 'RdPu',\n",
        "    'PuRd': 'PuRd',\n",
        "    'Blues_r': 'Blues_r',  # Reverse gradient\n",
        "    'Coolwarm': 'coolwarm',  # Diverging colors\n",
        "    'Seismic': 'seismic',    # High contrast\n",
        "    'Viridis': 'viridis',    # Perceptually uniform\n",
        "    'Plasma': 'plasma',\n",
        "    'Inferno': 'inferno',\n",
        "    'Magma': 'magma'\n",
        "}\n",
        "\n",
        "selected_theme = 'Greens'  # Change this to any of the themes above\n",
        "\n",
        "fsz = 16\n",
        "plt.rcParams.update({'font.size': fsz})  # Set base font size\n",
        "\n",
        "# آزمون مدل\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "all_test_preds = []\n",
        "all_test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        all_test_preds.extend(preds)\n",
        "        all_test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# محاسبه معیارهای ارزیابی\n",
        "accuracy = accuracy_score(all_test_labels, all_test_preds)\n",
        "f1 = f1_score(all_test_labels, all_test_preds,average='weighted') #,\n",
        "recall = recall_score(all_test_labels, all_test_preds,average='weighted')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Recall: {recall:.4f}')\n",
        "\n",
        "# محاسبه ماتریس اشتباه\n",
        "cm = confusion_matrix(all_test_labels, all_test_preds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# نمایش ماتریس اشتباه با نام کلاس و تم دلخواه\n",
        "plt.figure(figsize=(12, 10),dpi=300)\n",
        "sns.heatmap(cm,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap=themes[selected_theme],\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names,\n",
        "            annot_kws={\"size\": fsz+10})  # Increase annotation text size\n",
        "\n",
        "plt.title('Confusion Matrix of ConvNextV2 + SuperGAN', fontsize=fsz+10)  # Larger title fontweight='bold'\n",
        "plt.xlabel('Predicted Class', fontsize=fsz+10)  # Larger label\n",
        "plt.ylabel('Actual Class', fontsize=fsz+10)    # Larger label\n",
        "\n",
        "plt.xticks(fontsize=fsz+10,rotation=0)  # Increase tick label size\n",
        "plt.yticks(fontsize=fsz+10,rotation=0)\n",
        "\n",
        "plt.tight_layout()  # Prevent label cutoff\n",
        "# plt.savefig(os.path.join(save_dir, f'confusion_matrix_{selected_theme}.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7JuU7tOFEki4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_SUtVDc1WaKi",
        "cHsvop-5wb67",
        "Na2qw00SqAhD",
        "8QQcVQTT4t6P",
        "2uMPfftD4z_A",
        "OyWLwCUBTKNq",
        "Hy0pEreW-ap_",
        "viaRN_1kS6o_",
        "gBh6JykiyYYR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}